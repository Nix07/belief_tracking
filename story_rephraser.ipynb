{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "import json\n",
    "from utils import create_exps, prepare_data, get_story\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gpt4_chat(\n",
    "    api_key, messages, model=\"gpt-4o\", temperature=0.2, max_tokens=200\n",
    "):\n",
    "    \"\"\"\n",
    "    Queries GPT-4 Chat API with the given messages and parameters.\n",
    "\n",
    "    :param api_key: Your API Key for the OpenAI GPT\n",
    "    :param messages: A list of message dicts, where each dict contains 'role': 'user' or 'system', 'content': 'message text'\n",
    "    :param model: Which GPT model to use\n",
    "    :param temperature: Sampling temperature\n",
    "    :param max_tokens: Maximum number of tokens to generate\n",
    "    :return: The API response, including the generated text response\n",
    "    \"\"\"\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"OpenAI-Organization\": \"org-pqBwRmTwXkMQOPSIJPMi1ltR\",\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return (\n",
    "            response.json()\n",
    "            .get(\"choices\", [{}])[0]\n",
    "            .get(\"message\", {})\n",
    "            .get(\"content\", \"\")\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(f\"Error querying GPT-4 Chat API: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant that helps people paraphrase their short structured stories into more natural stories.\n",
    "\n",
    "Instructions:\n",
    " - Generate a more natural story based on the given structured story containing multiple characters, objects, containers and actions.\n",
    " - Make sure the generrate story has exactly the same meaning as the structured story.\n",
    " - Make sure the generated story has the same timeline as the structured story.\n",
    " - Make sure the generated story is coherent and grammatically correct.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Strctured Story: {story}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/SymbolicToM Datasets/Fixed and Unambiguous ToMi/\"\n",
    "with open(f\"{path}/test.txt\", \"r\") as f:\n",
    "    test_data = f.readlines()\n",
    "with open(f\"{path}/test.trace\", \"r\") as f:\n",
    "    test_trace = f.readlines()\n",
    "\n",
    "stories = get_story(test_data)\n",
    "processed_stories = prepare_data(stories, test_trace, n_priming_eps=0, add_question=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_data = {}\n",
    "\n",
    "for data in processed_stories:\n",
    "    if data[\"category\"] not in categorized_data:\n",
    "        categorized_data[data[\"category\"]] = [data]\n",
    "    else:\n",
    "        categorized_data[data[\"category\"]].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['first_order_true_belief', 'second_order_true_belief', 'second_order_false_belief', 'first_order_false_belief'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del categorized_data[\"memory\"], categorized_data[\"reality\"]\n",
    "categorized_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "first_order_true_belief:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "first_order_true_belief: 100%|██████████| 50/50 [01:35<00:00,  1.91s/it]\n",
      "second_order_true_belief: 100%|██████████| 50/50 [01:35<00:00,  1.91s/it]\n",
      "second_order_false_belief: 100%|██████████| 50/50 [01:34<00:00,  1.89s/it]\n",
      "first_order_false_belief: 100%|██████████| 50/50 [01:28<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "\n",
    "samples = []\n",
    "for category in categorized_data:\n",
    "    indices = random.sample(range(len(categorized_data[category])), n)\n",
    "    for idx in tqdm(indices, desc=category):\n",
    "        story = categorized_data[category][idx]\n",
    "        system_msg = {\"role\": \"system\", \"content\": system_prompt}\n",
    "        user_msg = {\"role\": \"user\", \"content\": user_prompt.format(story=story['input'])}\n",
    "        messages = [system_msg, user_msg]\n",
    "\n",
    "        api_key = \"sk-proj-0RkTDOm5cLKctlevusS0T3BlbkFJYDBjDQi5b2bIl1g5jFS2\"\n",
    "\n",
    "        response = query_gpt4_chat(api_key, messages)\n",
    "\n",
    "        samples.append({\n",
    "            \"input\": f\"{response}\\nQuestion: {story['question']}\\nAnswer:\",\n",
    "            \"category\": category,\n",
    "            \"target\": story[\"target\"],\n",
    "        })\n",
    "\n",
    "# Write samples to json file\n",
    "with open(f\"data/paraphrased_ToMi/dataset.json\", \"w\") as f:\n",
    "    json.dump(samples, f, indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:40<00:00, 10.13s/it]\n"
     ]
    }
   ],
   "source": [
    "for category in tqdm(categorized_data):\n",
    "    samples = []\n",
    "    with open(f\"priming_examples/original/{category}.txt\", \"r\") as f:\n",
    "        priming_examples = f.read().replace(\"\\\\n\", \"\\n\").split(\"\\n\\n\")\n",
    "\n",
    "    for example in priming_examples:\n",
    "        if example:\n",
    "            story = example[:example.index(\"Question\")].split(\":\")[-1].strip()\n",
    "            question = example[example.index(\"Question\"):].split(\"\\n\")[0].strip()\n",
    "            answer = example[example.index(\"Answer\"):].split(\":\")[-1].strip()\n",
    "\n",
    "            system_msg = {\"role\": \"system\", \"content\": system_prompt}\n",
    "            user_msg = {\"role\": \"user\", \"content\": user_prompt.format(story=story)}\n",
    "            messages = [system_msg, user_msg]\n",
    "\n",
    "            api_key = \"sk-proj-0RkTDOm5cLKctlevusS0T3BlbkFJYDBjDQi5b2bIl1g5jFS2\"\n",
    "\n",
    "            response = query_gpt4_chat(api_key, messages)\n",
    "\n",
    "            samples.append({\n",
    "                \"input\": f\"{response}\\n{question}\\nAnswer:\",\n",
    "                \"category\": category,\n",
    "                \"target\": \" \" + answer,\n",
    "            })\n",
    "    \n",
    "    with open(f\"priming_examples/paraphrases/{category}.json\", \"w\") as f:\n",
    "        json.dump(samples, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"priming_examples/first_order_false_belief.txt\", \"r\") as f:\n",
    "    priming_examples = f.read().replace(\"\\\\n\", \"\\n\").split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: bathtub\n"
     ]
    }
   ],
   "source": [
    "print(priming_examples[0][priming_examples[0].index(\"Answer:\"):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Where will Ethan look for the stockings?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priming_examples[0][priming_examples[0].index(\"Question\"):].split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Avery entered the staircase.\\nAlexander entered the staircase.\\nCharlotte entered the staircase.\\nThe cabbage is in the crate.\\nThe crate is in the staircase.\\nCharlotte exited the staircase.\\nAlexander moved the cabbage to the suitcase.\\nThe suitcase is in the staircase.\\n',\n",
       " 'target': ' crate',\n",
       " 'category': 'first_order_false_belief',\n",
       " 'question': 'Where will Charlotte look for the cabbage?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethan walked into the front yard, while Carter made his way into the pantry. Shortly after, Chloe also stepped into the front yard. In the yard, there was a crate containing some stockings. After a while, Ethan left the front yard, and Carter came out of the pantry. Chloe then took the stockings from the crate and placed them in the bathtub, which was also in the front yard. Eventually, Ethan returned to the front yard.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
