{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4\"\n",
    "\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from nnsight import CONFIG, LanguageModel\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.dataset import STORY_TEMPLATES\n",
    "# from src.utils import env_utils\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(10)\n",
    "\n",
    "CONFIG.set_default_api_key(\"d9e00ab7d4f74643b3176de0913f24a7\")\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "CONFIG.APP.REMOTE_LOGGING = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = {}\n",
    "all_containers= {}\n",
    "all_characters = json.load(open(os.path.join(\"../data/\", \"synthetic_entities\", \"characters.json\"), \"r\"))\n",
    "\n",
    "for TYPE, DCT in {\"states\": all_states, \"containers\": all_containers}.items():\n",
    "    ROOT = os.path.join(\n",
    "        \"../data/\", \"synthetic_entities\", TYPE\n",
    "    )\n",
    "    for file in os.listdir(ROOT):\n",
    "        file_path = os.path.join(ROOT, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            names = json.load(f)\n",
    "        DCT[file.split(\".\")[0]] = names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:34<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# model = LanguageModel(\"meta-llama/Meta-Llama-3.1-405B-Instruct\")\n",
    "model = LanguageModel(\"meta-llama/Meta-Llama-3-70B-Instruct\", cache_dir=\"/disk/u/nikhil/.cache/huggingface/hub/\", device_map=\"auto\", torch_dtype=torch.float16, dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "charac_indices = [131, 133, 146, 147, 158, 159]\n",
    "object_indices = [150, 151, 162, 163]\n",
    "state_indices = [155, 156, 167, 168]\n",
    "reversed_state_indices = [167, 168, 155, 156]\n",
    "reversed_object_indices = [162, 163, 150, 151]\n",
    "reversed_charac_indices = [133, 131, 158, 159, 146, 147]\n",
    "query_sent = [i for i in range(183, 195)]\n",
    "first_visibility_sent = [i for i in range(169, 176)]\n",
    "second_visibility_sent = [i for i in range(176, 183)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 40\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_state_pos_exps(STORY_TEMPLATES,\n",
    "                                all_characters,\n",
    "                                all_containers,\n",
    "                                all_states,\n",
    "                                train_size+valid_size,\n",
    "                                question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Nancy and Tony are working in a busy restaurant. To complete an order, Nancy grabs an opaque can and fills it with juice. Then Tony grabs another opaque dispenser and fills it with stout.\n",
      "Question: What does Nancy believe the can contains?\n",
      "Answer: juice\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Tony and Nancy are working in a busy restaurant. To complete an order, Tony grabs an opaque dispenser and fills it with stout. Then Nancy grabs another opaque can and fills it with juice.\n",
      "Question: What does Nancy believe the can contains?\n",
      "Answer: juice\n",
      "Target: ' stout'\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(train_dataset[idx]['corrupt_prompt'], train_dataset[idx]['corrupt_ans'])\n",
    "print(train_dataset[idx]['clean_prompt'], train_dataset[idx]['clean_ans'])\n",
    "print(f\"Target: '{train_dataset[idx]['target']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " water. port.\n",
      "\n",
      " port. water.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['corrupt_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][state_indices]))\n",
    "\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['clean_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][state_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 0!\n",
      "Validation started for 0\n",
      "#Rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0 | Validation accuracy: 0.00\n",
      "\n",
      "Training layer: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 10!\n",
      "Validation started for 10\n",
      "#Rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 10 | Validation accuracy: 0.00\n",
      "\n",
      "Training layer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 20!\n",
      "Validation started for 20\n",
      "#Rank: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 20 | Validation accuracy: 0.00\n",
      "\n",
      "Training layer: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 30!\n",
      "Validation started for 30\n",
      "#Rank: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 30 | Validation accuracy: 0.30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(0, 40, 10):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 1\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(state_indices):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(reversed_state_indices):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/state_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(state_indices):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(reversed_state_indices):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                        # model.model.layers[layer_idx].output[0][:, t] = alt_acts[t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 10: 0.0,\n",
       " 20: 0.0,\n",
       " 30: 0.3,\n",
       " 32: 0.6,\n",
       " 34: 1.0,\n",
       " 36: 0.7,\n",
       " 38: 0.425,\n",
       " 40: 0.025}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_obj_pos_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Uma and Jake are working in a busy restaurant. To complete an order, Uma grabs an opaque dispenser and fills it with port. Then Jake grabs another opaque glass and fills it with cocktail.\n",
      "Question: What does Jake believe the glass contains?\n",
      "Answer: cocktail\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Jake and Uma are working in a busy restaurant. To complete an order, Jake grabs an opaque glass and fills it with coffee. Then Uma grabs another opaque dispenser and fills it with monster.\n",
      "Question: What does Uma believe the glass contains?\n",
      "Answer: unknown\n",
      "Target:  monster\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flask and cup and\n",
      " cup and flask and\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['corrupt_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][object_indices]))\n",
    "\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['clean_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][object_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:17<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 12!\n",
      "Validation started for 12\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 0\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 1\n",
      "Layer: 10 | #Rank: 0\n",
      "Layer: 11 | #Rank: 2\n",
      "Layer: 12 | #Rank: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:42<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 12 | Validation accuracy: 0.06\n",
      "\n",
      "Training layer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:19<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 14!\n",
      "Validation started for 14\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 1\n",
      "Layer: 4 | #Rank: 0\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 1\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 2\n",
      "Layer: 10 | #Rank: 1\n",
      "Layer: 11 | #Rank: 2\n",
      "Layer: 12 | #Rank: 1\n",
      "Layer: 13 | #Rank: 14\n",
      "Layer: 14 | #Rank: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:44<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 14 | Validation accuracy: 0.38\n",
      "\n",
      "Training layer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:21<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 16!\n",
      "Validation started for 16\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 2\n",
      "Layer: 5 | #Rank: 2\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 6\n",
      "Layer: 10 | #Rank: 0\n",
      "Layer: 11 | #Rank: 1\n",
      "Layer: 12 | #Rank: 0\n",
      "Layer: 13 | #Rank: 11\n",
      "Layer: 14 | #Rank: 4\n",
      "Layer: 15 | #Rank: 8\n",
      "Layer: 16 | #Rank: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:45<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 16 | Validation accuracy: 0.69\n",
      "\n",
      "Training layer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:23<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 18!\n",
      "Validation started for 18\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 0\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 2\n",
      "Layer: 10 | #Rank: 0\n",
      "Layer: 11 | #Rank: 0\n",
      "Layer: 12 | #Rank: 1\n",
      "Layer: 13 | #Rank: 6\n",
      "Layer: 14 | #Rank: 0\n",
      "Layer: 15 | #Rank: 3\n",
      "Layer: 16 | #Rank: 13\n",
      "Layer: 17 | #Rank: 2\n",
      "Layer: 18 | #Rank: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:46<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 18 | Validation accuracy: 0.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(12, 20, 2):\n",
    "    mask = torch.ones(layer_idx+1, sing_vecs[layer_idx].shape[0], requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.01\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, alt_acts_charac, org_acts_state, org_acts_query_charac = defaultdict(dict), defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for l in range(layer_idx + 1):\n",
    "                        for t_idx, t in enumerate(charac_indices):\n",
    "                            alt_acts_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate(object_indices):\n",
    "                            alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(state_indices):\n",
    "                            org_acts_state[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate([-8, -7]):\n",
    "                            org_acts_query_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        for t_idx, t in enumerate(reversed_charac_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = alt_acts_charac[l][t_idx]\n",
    "\n",
    "                        sing_vec = sing_vecs[l].cuda()\n",
    "                        masked_vec = sing_vec * mask[l].unsqueeze(-1)\n",
    "                        proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "                        for t_idx, t in enumerate(reversed_object_indices):\n",
    "                            curr_output = model.model.layers[l].output[0][:, t].clone()\n",
    "                            alt_proj = torch.matmul(alt_acts[l][t_idx], proj_matrix)\n",
    "                            org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "                            modified_out = curr_output - org_proj + alt_proj\n",
    "                            model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                        for t_idx, t in enumerate([-8, -7]):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_query_charac[l][t_idx]\n",
    "\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(state_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_state[l][t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         for l in range(layer_idx+1):\n",
    "            #             mask[l].data.clamp_(0, 1)\n",
    "            #             rounded = torch.round(mask[l])\n",
    "            #             print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                for l in range(layer_idx+1):\n",
    "                    mask[l].data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "    rounded = torch.zeros(layer_idx+1, sing_vecs[layer_idx].shape[0], device=\"cuda\", dtype=torch.bfloat16)\n",
    "    with torch.inference_mode():\n",
    "        for l in range(layer_idx+1):\n",
    "            mask_data = mask[l].data.clone()\n",
    "            mask_data.clamp_(0, 1)\n",
    "            rounded[l] = torch.round(mask_data)\n",
    "            print(f\"Layer: {l} | #Rank: {(rounded[l] == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/object_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, alt_acts_charac, org_acts_state, org_acts_query_charac = defaultdict(dict), defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        for t_idx, t in enumerate(charac_indices):\n",
    "                            alt_acts_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate(object_indices):\n",
    "                            alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(state_indices):\n",
    "                            org_acts_state[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate([-8, -7]):\n",
    "                            org_acts_query_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        for t_idx, t in enumerate(reversed_charac_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = alt_acts_charac[l][t_idx]\n",
    "\n",
    "                        sing_vec = sing_vecs[l].cuda()\n",
    "                        masked_vec = sing_vec.to(rounded[l].device) * rounded[l].unsqueeze(-1)\n",
    "                        proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "                        for t_idx, t in enumerate(reversed_object_indices):\n",
    "                            curr_output = model.model.layers[l].output[0][:, t].clone()\n",
    "                            alt_proj = torch.matmul(alt_acts[l][t_idx], proj_matrix)\n",
    "                            org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "                            modified_out = curr_output - org_proj + alt_proj\n",
    "                            model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                        for t_idx, t in enumerate([-8, -7]):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_query_charac[l][t_idx]\n",
    "\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(state_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_state[l][t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.025,\n",
       " 5: 0.025,\n",
       " 10: 0.025,\n",
       " 12: 0.0625,\n",
       " 14: 0.375,\n",
       " 15: 0.375,\n",
       " 16: 0.6875,\n",
       " 18: 0.9,\n",
       " 20: 0.9125,\n",
       " 25: 0.9375,\n",
       " 30: 0.9125}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the valid_accs dict by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_charac_pos_exp(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Liz and Ray are working in a busy restaurant. To complete an order, Liz grabs an opaque pitcher and fills it with sprite. Then Ray grabs another opaque container and fills it with champagne.\n",
      "Question: What does Ray believe the container contains?\n",
      "Answer: champagne\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ray and Liz are working in a busy restaurant. To complete an order, Ray grabs an opaque container and fills it with milk. Then Liz grabs another opaque pitcher and fills it with monster.\n",
      "Question: What does Ray believe the pitcher contains?\n",
      "Answer: unknown\n",
      "Target:  monster\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dispenser and tun and\n",
      " tun and dispenser and\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['corrupt_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][object_indices]))\n",
    "\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['clean_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][object_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:27<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 12!\n",
      "Validation started for 12\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 1\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 2\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 1\n",
      "Layer: 7 | #Rank: 2\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 2\n",
      "Layer: 10 | #Rank: 5\n",
      "Layer: 11 | #Rank: 4\n",
      "Layer: 12 | #Rank: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:49<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 12 | Validation accuracy: 0.41\n",
      "\n",
      "Training layer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:30<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 14!\n",
      "Validation started for 14\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 1\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 1\n",
      "Layer: 5 | #Rank: 1\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 0\n",
      "Layer: 9 | #Rank: 1\n",
      "Layer: 10 | #Rank: 1\n",
      "Layer: 11 | #Rank: 3\n",
      "Layer: 12 | #Rank: 1\n",
      "Layer: 13 | #Rank: 10\n",
      "Layer: 14 | #Rank: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:51<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 14 | Validation accuracy: 0.78\n",
      "\n",
      "Training layer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:33<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 16!\n",
      "Validation started for 16\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 0\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 0\n",
      "Layer: 9 | #Rank: 1\n",
      "Layer: 10 | #Rank: 1\n",
      "Layer: 11 | #Rank: 1\n",
      "Layer: 12 | #Rank: 2\n",
      "Layer: 13 | #Rank: 5\n",
      "Layer: 14 | #Rank: 5\n",
      "Layer: 15 | #Rank: 1\n",
      "Layer: 16 | #Rank: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:52<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 16 | Validation accuracy: 0.86\n",
      "\n",
      "Training layer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:36<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 18!\n",
      "Validation started for 18\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 1\n",
      "Layer: 2 | #Rank: 1\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 1\n",
      "Layer: 5 | #Rank: 1\n",
      "Layer: 6 | #Rank: 1\n",
      "Layer: 7 | #Rank: 1\n",
      "Layer: 8 | #Rank: 2\n",
      "Layer: 9 | #Rank: 3\n",
      "Layer: 10 | #Rank: 3\n",
      "Layer: 11 | #Rank: 4\n",
      "Layer: 12 | #Rank: 3\n",
      "Layer: 13 | #Rank: 7\n",
      "Layer: 14 | #Rank: 5\n",
      "Layer: 15 | #Rank: 0\n",
      "Layer: 16 | #Rank: 3\n",
      "Layer: 17 | #Rank: 2\n",
      "Layer: 18 | #Rank: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:54<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 18 | Validation accuracy: 0.76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(12, 20, 2):\n",
    "    mask = torch.ones(layer_idx+1, sing_vecs[layer_idx].shape[0], requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.01\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state, org_acts_query_obj = defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for l in range(layer_idx + 1):\n",
    "                        for t_idx, t in enumerate(charac_indices):\n",
    "                            alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(object_indices + state_indices):\n",
    "                            org_acts_state[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate([-5, -4]):\n",
    "                            org_acts_query_obj[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        sing_vec = sing_vecs[l].cuda()\n",
    "                        masked_vec = sing_vec * mask[l].unsqueeze(-1)\n",
    "                        proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                        for t_idx, t in enumerate(reversed_charac_indices):\n",
    "                            curr_output = model.model.layers[l].output[0][:, t].clone()\n",
    "                            alt_proj = torch.matmul(alt_acts[l][t_idx], proj_matrix)\n",
    "                            org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                            modified_out = curr_output - org_proj + alt_proj\n",
    "                            model.model.layers[l].output[0][:, t] = modified_out\n",
    "                        \n",
    "                        for t_idx, t in enumerate([-5, -4]):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_query_obj[l][t_idx]\n",
    "                        \n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(object_indices + state_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_state[l][t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "            \n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         for l in range(layer_idx+1):\n",
    "            #             mask[l].data.clamp_(0, 1)\n",
    "            #             rounded = torch.round(mask[l])\n",
    "            #             print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                for l in range(layer_idx+1):\n",
    "                    mask[l].data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "    rounded = torch.zeros(layer_idx+1, sing_vecs[layer_idx].shape[0], device=\"cuda\", dtype=torch.bfloat16)\n",
    "    with torch.inference_mode():\n",
    "        for l in range(layer_idx+1):\n",
    "            mask_data = mask[l].data.clone()\n",
    "            mask_data.clamp_(0, 1)\n",
    "            rounded[l] = torch.round(mask_data)\n",
    "            print(f\"Layer: {l} | #Rank: {(rounded[l] == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/charac_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state, org_acts_query_charac = defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        for t_idx, t in enumerate(charac_indices):\n",
    "                            alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(object_indices + state_indices):\n",
    "                            org_acts_state[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "                        \n",
    "                        for t_idx, t in enumerate([-5, -4]):\n",
    "                            org_acts_query_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        sing_vec = sing_vecs[l].cuda()\n",
    "                        masked_vec = sing_vec.to(rounded[l].device) * rounded[l].unsqueeze(-1)\n",
    "                        proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                        for t_idx, t in enumerate(reversed_charac_indices):\n",
    "                            curr_output = model.model.layers[l].output[0][:, t].clone()\n",
    "                            alt_proj = torch.matmul(alt_acts[l][t_idx], proj_matrix)\n",
    "                            org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                            modified_out = curr_output - org_proj + alt_proj\n",
    "                            model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                        for t_idx, t in enumerate([-5, -4]):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_query_charac[l][t_idx]\n",
    "\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(object_indices + state_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_state[l][t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0625,\n",
       " 5: 0.0625,\n",
       " 10: 0.3375,\n",
       " 12: 0.4125,\n",
       " 14: 0.775,\n",
       " 15: 0.85,\n",
       " 16: 0.8625,\n",
       " 18: 0.7625,\n",
       " 20: 0.6875,\n",
       " 25: 0.675,\n",
       " 30: 0.5875}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = query_charac_pos(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Nick and Ruth are working in a busy restaurant. To complete an order, Nick grabs an opaque cup and fills it with bourbon. Then Ruth grabs another opaque pint and fills it with juice.\n",
      "Question: What does Nick believe the cup contains?\n",
      "Answer: bourbon\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ruth and Nick are working in a busy restaurant. To complete an order, Ruth grabs an opaque pint and fills it with tea. Then Nick grabs another opaque cup and fills it with soda.\n",
      "Question: What does Nick believe the pint contains?\n",
      "Answer: unknown\n",
      "Target:  tea\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Task Loss: -16.3281, L1 Loss: 25.0000, Total Loss: 8.6719\n",
      "#Causal SVs: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:03<00:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 2, Task Loss: -16.4219, L1 Loss: 19.8750, Total Loss: 5.7760\n",
      "#Causal SVs: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:06<00:24,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 4, Task Loss: -17.8125, L1 Loss: 14.8750, Total Loss: 2.7969\n",
      "#Causal SVs: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:09<00:21,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 6, Task Loss: -18.6406, L1 Loss: 9.8750, Total Loss: -0.1585\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:12<00:18,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 8, Task Loss: -17.1250, L1 Loss: 4.9375, Total Loss: -2.6997\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:15<00:15,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 10, Task Loss: -16.9844, L1 Loss: 0.0325, Total Loss: -5.1292\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:18<00:12,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 12, Task Loss: -16.9688, L1 Loss: 0.0236, Total Loss: -6.8436\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:21<00:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 14, Task Loss: -17.6875, L1 Loss: 0.0234, Total Loss: -8.3686\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:24<00:06,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 16, Task Loss: -18.9219, L1 Loss: 0.0237, Total Loss: -9.5523\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:27<00:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 18, Task Loss: -18.8281, L1 Loss: 0.0238, Total Loss: -10.3814\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 34!\n",
      "Validation started for 34\n",
      "#Rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 34 | Validation accuracy: 0.07\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(34, 36, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.025\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate([-8, -7]):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate([-8, -7]):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/query_charac_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate([-8, -7]):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate([-8, -7]):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = alt_acts[t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.075,\n",
       " 10: 0.0375,\n",
       " 12: 0.225,\n",
       " 14: 1.0,\n",
       " 16: 1.0,\n",
       " 18: 1.0,\n",
       " 20: 0.9,\n",
       " 30: 0.4625,\n",
       " 32: 0.1625,\n",
       " 34: 0.075}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = query_obj_pos(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Liz and Ray are working in a busy restaurant. To complete an order, Liz grabs an opaque pitcher and fills it with sprite. Then Ray grabs another opaque container and fills it with champagne.\n",
      "Question: What does Ray believe the container contains?\n",
      "Answer: champagne\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ray and Liz are working in a busy restaurant. To complete an order, Ray grabs an opaque container and fills it with milk. Then Liz grabs another opaque pitcher and fills it with monster.\n",
      "Question: What does Liz believe the container contains?\n",
      "Answer: unknown\n",
      "Target:  monster\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 22!\n",
      "Validation started for 22\n",
      "#Rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 22 | Validation accuracy: 0.91\n",
      "\n",
      "Training layer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 24!\n",
      "Validation started for 24\n",
      "#Rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 24 | Validation accuracy: 0.93\n",
      "\n",
      "Training layer: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 26!\n",
      "Validation started for 26\n",
      "#Rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 26 | Validation accuracy: 0.90\n",
      "\n",
      "Training layer: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 28!\n",
      "Validation started for 28\n",
      "#Rank: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 28 | Validation accuracy: 0.75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(22, 30, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.05\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate([-5, -4]):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate([-5, -4]):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/query_obj_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate([-5, -4]):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate([-5, -4]):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = alt_acts[t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 10: 0.0,\n",
       " 12: 0.0,\n",
       " 14: 0.6,\n",
       " 16: 0.6,\n",
       " 18: 0.8625,\n",
       " 20: 0.9,\n",
       " 22: 0.9125,\n",
       " 24: 0.925,\n",
       " 26: 0.9,\n",
       " 28: 0.75,\n",
       " 30: 0.2625}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct State Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vecs = defaultdict(dict)\n",
    "for l in range(model.config.num_hidden_layers):\n",
    "    sing_vecs[l] = torch.load(f\"../svd_results/CausalToM/no_visibility/last_token/singular_vecs/{l}.pt\").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = defaultdict(dict)\n",
    "path = \"/disk/u/nikhil/mind/patching_results/CausalToM/Meta-Llama-3-70B-Instruct/no_visibility/position_transmitter\"\n",
    "# Find all files in the directory\n",
    "files = os.listdir(path)\n",
    "\n",
    "for file in files:\n",
    "    data = json.load(open(os.path.join(path, file), \"r\"))\n",
    "    masks[int(file.split(\".\")[0])] = data[\"singular_vector\"][\"metadata\"][\"mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_pos_trans_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Heidi and Jeff are working in a busy restaurant. To complete an order, Heidi grabs an opaque glass and fills it with bourbon. Then Jeff grabs another opaque jar and fills it with champagne.\n",
      "Question: What does Heidi believe the glass contains?\n",
      "Answer: bourbon\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Jeff and Heidi are working in a busy restaurant. To complete an order, Jeff grabs an opaque jar and fills it with sprite. Then Heidi grabs another opaque glass and fills it with ale.\n",
      "Question: What does Heidi believe the glass contains?\n",
      "Answer: ale\n",
      "Target:  sprite\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 40!\n",
      "Validation started for 40\n",
      "#Rank: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 40 | Validation accuracy: 0.86\n",
      "\n",
      "Training layer: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:29<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 45!\n",
      "Validation started for 45\n",
      "#Rank: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 45 | Validation accuracy: 0.86\n",
      "\n",
      "Training layer: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 50!\n",
      "Validation started for 50\n",
      "#Rank: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 50 | Validation accuracy: 0.84\n",
      "\n",
      "Training layer: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:26<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 55!\n",
      "Validation started for 55\n",
      "#Rank: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 55 | Validation accuracy: 0.24\n",
      "\n",
      "Training layer: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:24<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 60!\n",
      "Validation started for 60\n",
      "#Rank: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 60 | Validation accuracy: 0.11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(40, 65, 5):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.1\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        # torch.save(rounded, f\"../masks/toy/correct_state_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                    # model.model.layers[layer_idx].output[0][:, -1] = alt_acts\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    # valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Rank: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:01<00:26,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: beer, Target: beer\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: cocoa, Target: cocoa\n",
      "Predicted: rum, Target: rum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:02<00:22,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: espresso, Target: espresso\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: wine, Target: wine\n",
      "Predicted: monster, Target: monster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:03<00:19,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: stout, Target: water\n",
      "Predicted: cocoa, Target: cocoa\n",
      "Predicted: float, Target: float\n",
      "Predicted: stout, Target: stout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:04<00:19,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: flute, Target: ale\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: juice, Target: juice\n",
      "Predicted: gin, Target: gin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:06<00:17,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: bourbon, Target: bourbon\n",
      "Predicted: port, Target: port\n",
      "Predicted: monster, Target: monster\n",
      "Predicted: tea, Target: tea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:07<00:16,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: stout, Target: stout\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: cocktail, Target: water\n",
      "Predicted: cocoa, Target: cocoa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:08<00:15,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: float, Target: float\n",
      "Predicted: bourbon, Target: bourbon\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: milk, Target: milk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:09<00:15,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: bourbon, Target: bourbon\n",
      "Predicted: ale, Target: ale\n",
      "Predicted: bourbon, Target: bourbon\n",
      "Predicted: sprite, Target: sprite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:11<00:13,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: soda, Target: soda\n",
      "Predicted: gin, Target: gin\n",
      "Predicted: ale, Target: ale\n",
      "Predicted: punch, Target: punch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:12<00:12,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: gin, Target: gin\n",
      "Predicted: water, Target: water\n",
      "Predicted: stout, Target: stout\n",
      "Predicted: porter, Target: porter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:13<00:11,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: wine, Target: wine\n",
      "Predicted: beer, Target: cocktail\n",
      "Predicted: beer, Target: beer\n",
      "Predicted: gin, Target: gin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:14<00:09,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: gin, Target: gin\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: punch, Target: punch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:15<00:08,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tea, Target: tea\n",
      "Predicted: cocoa, Target: cocoa\n",
      "Predicted: rum, Target: rum\n",
      "Predicted: water, Target: water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:17<00:07,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: port, Target: port\n",
      "Predicted: tea, Target: tea\n",
      "Predicted: champagne, Target: champagne\n",
      "Predicted: gin, Target: gin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:18<00:06,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: beer, Target: beer\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: soda, Target: soda\n",
      "Predicted: champagne, Target: champagne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:19<00:05,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: juice, Target: cocktail\n",
      "Predicted: sprite, Target: sprite\n",
      "Predicted: ale, Target: ale\n",
      "Predicted: gin, Target: gin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:20<00:03,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: coffee, Target: coffee\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: beer, Target: cocktail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:22<00:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: bourbon, Target: cocktail\n",
      "Predicted: cocoa, Target: cocoa\n",
      "Predicted: sprite, Target: sprite\n",
      "Predicted: ale, Target: ale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:23<00:01,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: water, Target: cocktail\n",
      "Predicted: beer, Target: beer\n",
      "Predicted: tea, Target: tea\n",
      "Predicted: espresso, Target: espresso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: juice, Target: juice\n",
      "Predicted: soda, Target: soda\n",
      "Predicted: juice, Target: juice\n",
      "Predicted: ale, Target: cocoa\n",
      "Layer: 40 | Validation accuracy: 0.89\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layer_idx = 40\n",
    "mask = torch.tensor(masks[layer_idx])\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    mask_data = mask.data.clone()\n",
    "    mask_data.clamp_(0, 1)\n",
    "    rounded = torch.round(mask_data)\n",
    "    # rounded = torch.ones_like(rounded)\n",
    "    print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "    # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "    # torch.save(rounded, f\"../masks/toy/correct_state_oid/{layer_idx}.pt\")\n",
    "\n",
    "    for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "        alt_prompts = batch[\"corrupt_prompt\"]\n",
    "        org_prompts = batch[\"clean_prompt\"]\n",
    "        targets = batch[\"target\"]\n",
    "        target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "        batch_size = target_tokens.size(0)\n",
    "\n",
    "        alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "        with model.trace() as tracer:\n",
    "            with tracer.invoke(alt_prompts):\n",
    "                alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "            with tracer.invoke(org_prompts):\n",
    "                sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                modified_out = curr_output - org_proj + alt_proj\n",
    "                model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                # model.model.layers[layer_idx].output[0][:, -1] = alt_acts\n",
    "\n",
    "                del sing_vec, proj_matrix, masked_vec\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "        pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            pred_token = model.tokenizer.decode(pred[i])\n",
    "            print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "            if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "        del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "# valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{30: 0.0125,\n",
       " 32: 0.0,\n",
       " 34: 0.975,\n",
       " 36: 0.8,\n",
       " 38: 0.9625,\n",
       " 40: 0.0,\n",
       " 45: 0.0,\n",
       " 50: 0.0,\n",
       " 55: 0.025,\n",
       " 60: 0.0625}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vecs = defaultdict(dict)\n",
    "for l in range(model.config.num_hidden_layers):\n",
    "    sing_vecs[l] = torch.load(f\"../svd_results/BigToM/last_token/singular_vecs/{l}.pt\").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = defaultdict(dict)\n",
    "path = \"/disk/u/nikhil/mind/patching_results/BigToM/Meta-Llama-3-70B-Instruct/answer\"\n",
    "# Find all files in the directory\n",
    "files = os.listdir(path)\n",
    "\n",
    "for file in files:\n",
    "    data = json.load(open(os.path.join(path, file), \"r\"))\n",
    "    masks[int(file.split(\".\")[0])] = data[\"singular_vector\"][\"metadata\"][\"mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_value_fetcher_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Jack and Mike are working in a busy restaurant. To complete an order, Jack grabs an opaque bottle and fills it with tea. Then Mike grabs another opaque tun and fills it with monster.\n",
      "Question: What does Mike believe the tun contains?\n",
      "Answer:  monster\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ben and Quinn are working in a busy restaurant. To complete an order, Ben grabs an opaque tun and fills it with gin. Then Quinn grabs another opaque jug and fills it with milk.\n",
      "Question: What does Quinn believe the jug contains?\n",
      "Answer:  milk\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_target'])\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 56!\n",
      "Validation started for 56\n",
      "#Rank: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 56 | Validation accuracy: 0.65\n",
      "\n",
      "Training layer: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 58!\n",
      "Validation started for 58\n",
      "#Rank: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 58 | Validation accuracy: 0.86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(56, 60, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.4\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"corrupt_target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/value_fetcher/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"corrupt_target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                    # model.model.layers[layer_idx].output[0][:, -1] = alt_acts\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Rank: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:00<00:18,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: port, Target: float\n",
      "Predicted: punch, Target: float\n",
      "Predicted: water, Target: punch\n",
      "Predicted: juice, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:02<00:20,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: rum\n",
      "Predicted: gin, Target: coffee\n",
      "Predicted: stout, Target: milk\n",
      "Predicted: rum, Target: punch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:03<00:19,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: bourbon, Target: punch\n",
      "Predicted: ale, Target: beer\n",
      "Predicted: milk, Target: port\n",
      "Predicted: gin, Target: coffee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:04<00:18,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: juice, Target: beer\n",
      "Predicted: coffee, Target: float\n",
      "Predicted: cocoa, Target: milk\n",
      "Predicted: port, Target: milk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:05<00:17,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: sprite, Target: cocoa\n",
      "Predicted: rum, Target: port\n",
      "Predicted: cocoa, Target: gin\n",
      "Predicted: float, Target: tea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:07<00:16,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tea, Target: monster\n",
      "Predicted: champagne, Target: rum\n",
      "Predicted: rum, Target: ale\n",
      "Predicted: monster, Target: float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:08<00:15,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tea, Target: monster\n",
      "Predicted: bourbon, Target: wine\n",
      "Predicted: cocktail, Target: coffee\n",
      "Predicted: float, Target: gin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:09<00:13,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: stout, Target: wine\n",
      "Predicted: stout, Target: cocoa\n",
      "Predicted: monster, Target: espresso\n",
      "Predicted: rum, Target: tea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:10<00:13,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: bourbon, Target: soda\n",
      "Predicted: water, Target: tea\n",
      "Predicted: wine, Target: stout\n",
      "Predicted: coffee, Target: champagne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:11<00:11,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: sprite, Target: soda\n",
      "Predicted: rum, Target: milk\n",
      "Predicted: water, Target: coffee\n",
      "Predicted: rum, Target: porter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:12<00:10,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: soda, Target: rum\n",
      "Predicted: ale, Target: juice\n",
      "Predicted: porter, Target: bourbon\n",
      "Predicted: cocktail, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:14<00:09,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: sprite, Target: ale\n",
      "Predicted: cocktail, Target: champagne\n",
      "Predicted: monster, Target: ale\n",
      "Predicted: champagne, Target: beer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:15<00:08,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: punch, Target: monster\n",
      "Predicted: espresso, Target: milk\n",
      "Predicted: sprite, Target: rum\n",
      "Predicted: espresso, Target: juice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:16<00:07,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: float, Target: ale\n",
      "Predicted: water, Target: stout\n",
      "Predicted: champagne, Target: sprite\n",
      "Predicted: cocktail, Target: coffee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:17<00:05,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: cocoa, Target: espresso\n",
      "Predicted: monster, Target: milk\n",
      "Predicted: espresso, Target: beer\n",
      "Predicted: float, Target: rum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:19<00:04,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: punch, Target: float\n",
      "Predicted: bourbon, Target: espresso\n",
      "Predicted: beer, Target: milk\n",
      "Predicted: float, Target: monster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:20<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: port, Target: gin\n",
      "Predicted: punch, Target: wine\n",
      "Predicted: sprite, Target: sprite\n",
      "Predicted: gin, Target: wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:21<00:02,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: soda, Target: soda\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: tea, Target: monster\n",
      "Predicted: porter, Target: float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:22<00:01,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: coffee, Target: gin\n",
      "Predicted: float, Target: monster\n",
      "Predicted: soda, Target: bourbon\n",
      "Predicted: sprite, Target: float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: coffee, Target: gin\n",
      "Predicted: wine, Target: champagne\n",
      "Predicted: rum, Target: port\n",
      "Predicted: float, Target: cocktail\n",
      "Layer: 60 | Validation accuracy: 0.04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layer_idx = 60\n",
    "mask = torch.tensor(masks[layer_idx])\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    mask_data = mask.data.clone()\n",
    "    mask_data.clamp_(0, 1)\n",
    "    rounded = torch.round(mask_data)\n",
    "    print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "    for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "        alt_prompts = batch[\"corrupt_prompt\"]\n",
    "        org_prompts = batch[\"clean_prompt\"]\n",
    "        targets = batch[\"corrupt_target\"]\n",
    "        target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "        batch_size = target_tokens.size(0)\n",
    "\n",
    "        alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "        with model.trace() as tracer:\n",
    "            with tracer.invoke(alt_prompts):\n",
    "                alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "            with tracer.invoke(org_prompts):\n",
    "                sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                modified_out = curr_output - org_proj + alt_proj\n",
    "                model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                # model.model.layers[layer_idx].output[0][:, -1] = alt_acts\n",
    "\n",
    "                del sing_vec, proj_matrix, masked_vec\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "        pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            pred_token = model.tokenizer.decode(pred[i])\n",
    "            print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "            if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "        del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: 0.0625,\n",
       " 55: 0.2625,\n",
       " 56: 0.65,\n",
       " 58: 0.8625,\n",
       " 60: 0.8375,\n",
       " 65: 0.95,\n",
       " 70: 0.9375,\n",
       " 75: 0.9875}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vecs = defaultdict(dict)\n",
    "for l in range(model.config.num_hidden_layers):\n",
    "    sing_vecs[l] = torch.load(f\"../svd_results/belief_tracking/second_visibility_sent/singular_vecs/{l}.pt\").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 40\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_unidirectional_visibility_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             additional_characs=False)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ray and Liz are working in a busy restaurant. To complete an order, Ray grabs an opaque container and fills it with coffee. Then Liz grabs another opaque pitcher and fills it with cocoa. Liz cannot observe Ray's actions. Ray can observe Liz's actions.\n",
      "Question: What does Ray believe the pitcher contains?\n",
      "Answer: cocoa\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Max and Karen are working in a busy restaurant. To complete an order, Max grabs an opaque tun and fills it with port. Then Karen grabs another opaque dispenser and fills it with water. Karen cannot observe Max's actions. Max cannot observe Karen's actions.\n",
      "Question: What does Max believe the dispenser contains?\n",
      "Answer: unknown\n",
      "Target:  water\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ray can observe Liz's actions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = model.tokenizer(dataset[idx]['corrupt_prompt'], return_tensors=\"pt\")\n",
    "print(model.tokenizer.decode(tokens.input_ids[0][second_visibility_sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Task Loss: -18.1875, L1 Loss: 52.5000, Total Loss: 34.3125\n",
      "Rank: 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:05<00:51,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 2, Task Loss: -19.5312, L1 Loss: 43.2500, Total Loss: 29.6094\n",
      "Rank: 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:09<00:36,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 4, Task Loss: -19.8594, L1 Loss: 34.0000, Total Loss: 24.4656\n",
      "Rank: 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:15<00:35,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 6, Task Loss: -19.9375, L1 Loss: 25.2500, Total Loss: 19.4955\n",
      "Rank: 549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:20<00:31,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 8, Task Loss: -20.1875, L1 Loss: 16.2500, Total Loss: 14.6997\n",
      "Rank: 452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:26<00:28,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 10, Task Loss: -20.0312, L1 Loss: 7.3125, Total Loss: 10.0682\n",
      "Rank: 387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:30<00:18,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 12, Task Loss: -20.9688, L1 Loss: 5.4062, Total Loss: 6.1562\n",
      "Rank: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:36<00:15,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 14, Task Loss: -19.7812, L1 Loss: 4.7188, Total Loss: 3.3146\n",
      "Rank: 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:41<00:11,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 16, Task Loss: -20.4844, L1 Loss: 4.2500, Total Loss: 0.9651\n",
      "Rank: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:47<00:05,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 18, Task Loss: -20.4375, L1 Loss: 3.9375, Total Loss: -0.8758\n",
      "Rank: 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:51<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 26!\n",
      "Validation started for 26\n",
      "#Rank: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: bourbon, Target: bourbon\n",
      "Predicted: sprite, Target: sprite\n",
      "Predicted: champagne, Target: champagne\n",
      "Predicted: bourbon, Target: bourbon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: port, Target: port\n",
      "Predicted: stout, Target: stout\n",
      "Predicted: espresso, Target: espresso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: water, Target: water\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: soda, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:08,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: ale, Target: ale\n",
      "Predicted: gin, Target: gin\n",
      "Predicted: ale, Target: ale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:06,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: cocktail, Target: sprite\n",
      "Predicted: unknown, Target: port\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: cocktail, Target: cocktail\n",
      "Predicted: unknown, Target: rum\n",
      "Predicted: tea, Target: tea\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: port, Target: port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:11<00:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: beer, Target: beer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:12<00:02,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: stout, Target: stout\n",
      "Predicted: champagne, Target: champagne\n",
      "Predicted: unknown, Target: milk\n",
      "Predicted: port, Target: port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:13<00:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: champagne, Target: champagne\n",
      "Predicted: milk, Target: milk\n",
      "Predicted: stout, Target: stout\n",
      "Predicted: soda, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ale, Target: ale\n",
      "Predicted: milk, Target: milk\n",
      "Predicted: stout, Target: stout\n",
      "Predicted: coffee, Target: coffee\n",
      "Layer: 26 | Validation accuracy: 0.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(26, 27, 1):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.015\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts = defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(second_visibility_sent):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(second_visibility_sent):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if bi % 2 == 0:\n",
    "                mean_loss = epoch_loss / (bi + 1)\n",
    "                print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "                    f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "                with torch.no_grad():\n",
    "                    mask.data.clamp_(0, 1)\n",
    "                    rounded = torch.round(mask)\n",
    "                    print(f\"Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        # torch.save(rounded, f\"../masks/toy/visibility_sentence/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts = defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(second_visibility_sent):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(second_visibility_sent):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "                    \n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    # valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation started for 26\n",
      "#Rank: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:31,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: bourbon, Target: bourbon\n",
      "Predicted: sprite, Target: sprite\n",
      "Predicted: champagne, Target: champagne\n",
      "Predicted: bourbon, Target: bourbon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:05<00:19,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: port, Target: port\n",
      "Predicted: stout, Target: stout\n",
      "Predicted: espresso, Target: espresso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:07<00:15,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: water, Target: water\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: soda, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:10<00:16,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: ale, Target: ale\n",
      "Predicted: gin, Target: gin\n",
      "Predicted: ale, Target: ale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:12<00:11,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: cocktail, Target: sprite\n",
      "Predicted: unknown, Target: port\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: cocktail, Target: cocktail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:14<00:08,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: unknown, Target: rum\n",
      "Predicted: tea, Target: tea\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: port, Target: port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:17<00:07,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: beer, Target: beer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:19<00:04,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: stout, Target: stout\n",
      "Predicted: champagne, Target: champagne\n",
      "Predicted: unknown, Target: milk\n",
      "Predicted: port, Target: port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:21<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: champagne, Target: champagne\n",
      "Predicted: milk, Target: milk\n",
      "Predicted: stout, Target: stout\n",
      "Predicted: soda, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ale, Target: ale\n",
      "Predicted: milk, Target: milk\n",
      "Predicted: stout, Target: stout\n",
      "Predicted: coffee, Target: coffee\n",
      "Layer: 26 | Validation accuracy: 0.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation started for {layer_idx}\")\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    mask_data = mask.data.clone()\n",
    "    mask_data.clamp_(0, 1)\n",
    "    rounded = torch.round(mask_data)\n",
    "    print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "    # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "    # torch.save(rounded, f\"../masks/toy/visibility_sentence/{layer_idx}.pt\")\n",
    "\n",
    "    for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "        alt_prompts = batch[\"corrupt_prompt\"]\n",
    "        org_prompts = batch[\"clean_prompt\"]\n",
    "        targets = batch[\"target\"]\n",
    "        target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "        batch_size = target_tokens.size(0)\n",
    "\n",
    "        alt_acts, query_acts = defaultdict(dict), defaultdict(dict)\n",
    "        with model.trace() as tracer:\n",
    "            with tracer.invoke(alt_prompts):\n",
    "                for l in range(model.config.num_hidden_layers):\n",
    "                    for t_idx, t in enumerate(second_visibility_sent):\n",
    "                        alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "                    \n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        query_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "            with tracer.invoke(org_prompts):\n",
    "                # for l in range(0, 30):\n",
    "                #     for t_idx, t in enumerate(query_sent):\n",
    "                #         model.model.layers[l].output[0][:, t] = query_acts[l][t_idx]\n",
    "\n",
    "                sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                for t_idx, t in enumerate(second_visibility_sent):\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts[layer_idx][t_idx], proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                del sing_vec, proj_matrix, masked_vec\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "        pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            pred_token = model.tokenizer.decode(pred[i])\n",
    "            print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "            if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "        del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "# valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 5: 0.0,\n",
       " 10: 1.0,\n",
       " 15: 1.0,\n",
       " 20: 1.0,\n",
       " 25: 0.975,\n",
       " 30: 0.975,\n",
       " 31: 0.0,\n",
       " 32: 0.0,\n",
       " 33: 0.0,\n",
       " 35: 0.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vecs = defaultdict(dict)\n",
    "for l in range(model.config.num_hidden_layers):\n",
    "    sing_vecs[l] = torch.load(f\"../svd_results/belief_tracking/query_sent_with_vis/singular_vecs/{l}.pt\").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_unidirectional_visibility_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ray and Liz are working in a busy restaurant. To complete an order, Ray grabs an opaque container and fills it with coffee. Then Liz grabs another opaque pitcher and fills it with cocoa. Liz cannot observe Ray's actions. Ray can observe Liz's actions.\n",
      "Question: What does Ray believe the pitcher contains?\n",
      "Answer: cocoa\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Max and Karen are working in a busy restaurant. To complete an order, Max grabs an opaque tun and fills it with port. Then Karen grabs another opaque dispenser and fills it with water. Karen cannot observe Max's actions. Max cannot observe Karen's actions.\n",
      "Question: What does Max believe the dispenser contains?\n",
      "Answer: unknown\n",
      "Target: ' water'\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: '{dataset[idx]['target']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:45<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 16!\n",
      "Validation started for 16\n",
      "#Rank: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:23<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 16 | Validation accuracy: 0.30\n",
      "\n",
      "Training layer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:41<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 18!\n",
      "Validation started for 18\n",
      "#Rank: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 18 | Validation accuracy: 0.39\n",
      "\n",
      "Training layer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:44<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 20!\n",
      "Validation started for 20\n",
      "#Rank: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:23<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 20 | Validation accuracy: 0.49\n",
      "\n",
      "Training layer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 22!\n",
      "Validation started for 22\n",
      "#Rank: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:23<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 22 | Validation accuracy: 0.46\n",
      "\n",
      "Training layer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:42<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 24!\n",
      "Validation started for 24\n",
      "#Rank: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:23<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 24 | Validation accuracy: 0.71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(16, 26, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.02\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_query_sent_acts, alt_second_vis_sent = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        alt_query_sent_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                    for l in range(25, 30):\n",
    "                        for t_idx, t in enumerate(second_visibility_sent):\n",
    "                            alt_second_vis_sent[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_query_sent_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    for l in range(25, 30):\n",
    "                        for t_idx, t in enumerate(second_visibility_sent):\n",
    "                            model.model.layers[l].output[0][:, t] = alt_second_vis_sent[l][t_idx]\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        # torch.save(rounded, f\"../masks/toy/visibility_sentence/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_query_sent_acts, alt_second_vis_sent = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        alt_query_sent_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                    for l in range(25, 30):\n",
    "                        for t_idx, t in enumerate(second_visibility_sent):\n",
    "                            alt_second_vis_sent[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_query_sent_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "                    \n",
    "                    for l in range(25, 30):\n",
    "                        for t_idx, t in enumerate(second_visibility_sent):\n",
    "                            model.model.layers[l].output[0][:, t] = alt_second_vis_sent[l][t_idx]\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_query_sent_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    # valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.1375,\n",
       " 5: 0.1375,\n",
       " 10: 0.125,\n",
       " 15: 0.3625,\n",
       " 16: 0.3,\n",
       " 18: 0.3875,\n",
       " 20: 0.4875,\n",
       " 22: 0.4625,\n",
       " 24: 0.7125,\n",
       " 25: 0.8125,\n",
       " 30: 0.825}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsed Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_unidirectional_visibility_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ray and Liz are working in a busy restaurant. To complete an order, Ray grabs an opaque container and fills it with coffee. Then Liz grabs another opaque pitcher and fills it with cocoa. Liz cannot observe Ray's actions. Ray can observe Liz's actions.\n",
      "Question: What does Ray believe the pitcher contains?\n",
      "Answer: cocoa\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Max and Karen are working in a busy restaurant. To complete an order, Max grabs an opaque tun and fills it with port. Then Karen grabs another opaque dispenser and fills it with water. Karen cannot observe Max's actions. Max cannot observe Karen's actions.\n",
      "Question: What does Max believe the dispenser contains?\n",
      "Answer: unknown\n",
      "Target: ' water'\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: '{dataset[idx]['target']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:38<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 31!\n",
      "Validation started for 31\n",
      "#Rank: 318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:23<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 31 | Validation accuracy: 0.71\n",
      "\n",
      "Training layer: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:40<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 32!\n",
      "Validation started for 32\n",
      "#Rank: 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:23<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 32 | Validation accuracy: 0.76\n",
      "\n",
      "Training layer: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:39<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 33!\n",
      "Validation started for 33\n",
      "#Rank: 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:23<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 33 | Validation accuracy: 0.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(31, 34, 1):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.01\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_query_sent_acts = defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        alt_query_sent_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_query_sent_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/parsed_question/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_query_sent_acts = defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        alt_query_sent_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(query_sent):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_query_sent_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_query_sent_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 5: 0.0125,\n",
       " 10: 0.0,\n",
       " 15: 0.0,\n",
       " 20: 0.0,\n",
       " 25: 0.0,\n",
       " 30: 0.475,\n",
       " 31: 0.7125,\n",
       " 32: 0.7625,\n",
       " 33: 0.9}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 28,\n",
       " 5: 56,\n",
       " 10: 79,\n",
       " 15: 80,\n",
       " 20: 153,\n",
       " 25: 209,\n",
       " 30: 332,\n",
       " 31: 318,\n",
       " 32: 268,\n",
       " 33: 206}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort rank by key\n",
    "rank = dict(sorted(rank.items()))\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
