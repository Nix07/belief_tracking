{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "env.yml not found in /disk/u/nikhil/mind!\n",
      "Setting MODEL_ROOT=\"\". Models will now be downloaded to conda env cache, if not already there\n",
      "Other defaults are set to:\n",
      "    DATA_DIR = \"data\"\n",
      "    RESULTS_DIR = \"results\"\n",
      "    HPARAMS_DIR = \"hparams\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4\"\n",
    "\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any, List, Optional\n",
    "import nnsight\n",
    "from nnsight import CONFIG, LanguageModel\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from einops import einsum\n",
    "import time\n",
    "from einops import rearrange, reduce\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.dataset import SampleV3, DatasetV3, STORY_TEMPLATES\n",
    "from src.utils import env_utils\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(10)\n",
    "\n",
    "CONFIG.set_default_api_key(\"d9e00ab7d4f74643b3176de0913f24a7\")\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "CONFIG.APP.REMOTE_LOGGING = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = {}\n",
    "all_containers= {}\n",
    "all_characters = json.load(open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"synthetic_entities\", \"characters.json\"), \"r\"))\n",
    "\n",
    "for TYPE, DCT in {\"states\": all_states, \"containers\": all_containers}.items():\n",
    "    ROOT = os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \"synthetic_entities\", TYPE\n",
    "    )\n",
    "    for file in os.listdir(ROOT):\n",
    "        file_path = os.path.join(ROOT, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            names = json.load(f)\n",
    "        DCT[file.split(\".\")[0]] = names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:36<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# model = LanguageModel(\"meta-llama/Meta-Llama-3.1-405B-Instruct\")\n",
    "model = LanguageModel(\"meta-llama/Meta-Llama-3-70B-Instruct\", cache_dir=\"/disk/u/nikhil/.cache/huggingface/hub/\", device_map=\"auto\", torch_dtype=torch.float16, dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Singular Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vecs = defaultdict(dict)\n",
    "for l in range(model.config.num_hidden_layers):\n",
    "    sing_vecs[l] = torch.load(f\"../svd_results/belief_tracking/second_visibility_sent/singular_vecs/{l}.pt\").cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "charac_indices = [131, 133, 146, 147, 158, 159]\n",
    "object_indices = [150, 151, 162, 163]\n",
    "state_indices = [155, 156, 167, 168]\n",
    "reversed_state_indices = [167, 168, 155, 156]\n",
    "reversed_object_indices = [162, 163, 150, 151]\n",
    "reversed_charac_indices = [133, 131, 158, 159, 146, 147]\n",
    "query_sent = [i for i in range(169, 181)]\n",
    "first_visibility_sent = [i for i in range(169, 176)]\n",
    "second_visibility_sent = [i for i in range(176, 183)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 40\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_state_pos_exps(STORY_TEMPLATES,\n",
    "                                all_characters,\n",
    "                                all_containers,\n",
    "                                all_states,\n",
    "                                train_size+valid_size,\n",
    "                                question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Nancy and Tony are working in a busy restaurant. To complete an order, Nancy grabs an opaque can and fills it with juice. Then Tony grabs another opaque dispenser and fills it with stout.\n",
      "Question: What does Nancy believe the can contains?\n",
      "Answer: juice\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Tony and Nancy are working in a busy restaurant. To complete an order, Tony grabs an opaque dispenser and fills it with stout. Then Nancy grabs another opaque can and fills it with juice.\n",
      "Question: What does Nancy believe the can contains?\n",
      "Answer: juice\n",
      "Target: ' stout'\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(train_dataset[idx]['corrupt_prompt'], train_dataset[idx]['corrupt_ans'])\n",
    "print(train_dataset[idx]['clean_prompt'], train_dataset[idx]['clean_ans'])\n",
    "print(f\"Target: '{train_dataset[idx]['target']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " water. port.\n",
      "\n",
      " port. water.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['corrupt_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][state_indices]))\n",
    "\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['clean_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][state_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 0!\n",
      "Validation started for 0\n",
      "#Rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0 | Validation accuracy: 0.00\n",
      "\n",
      "Training layer: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 10!\n",
      "Validation started for 10\n",
      "#Rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 10 | Validation accuracy: 0.00\n",
      "\n",
      "Training layer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 20!\n",
      "Validation started for 20\n",
      "#Rank: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 20 | Validation accuracy: 0.00\n",
      "\n",
      "Training layer: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 30!\n",
      "Validation started for 30\n",
      "#Rank: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 30 | Validation accuracy: 0.30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(0, 40, 10):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 1\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(state_indices):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(reversed_state_indices):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/state_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(state_indices):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(reversed_state_indices):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                        # model.model.layers[layer_idx].output[0][:, t] = alt_acts[t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 10: 0.0,\n",
       " 20: 0.0,\n",
       " 30: 0.3,\n",
       " 32: 0.6,\n",
       " 34: 1.0,\n",
       " 36: 0.7,\n",
       " 38: 0.425,\n",
       " 40: 0.025}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_obj_pos_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Uma and Jake are working in a busy restaurant. To complete an order, Uma grabs an opaque dispenser and fills it with port. Then Jake grabs another opaque glass and fills it with cocktail.\n",
      "Question: What does Jake believe the glass contains?\n",
      "Answer: cocktail\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Jake and Uma are working in a busy restaurant. To complete an order, Jake grabs an opaque glass and fills it with coffee. Then Uma grabs another opaque dispenser and fills it with monster.\n",
      "Question: What does Uma believe the glass contains?\n",
      "Answer: unknown\n",
      "Target:  monster\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flask and cup and\n",
      " cup and flask and\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['corrupt_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][object_indices]))\n",
    "\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['clean_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][object_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:17<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 12!\n",
      "Validation started for 12\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 0\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 1\n",
      "Layer: 10 | #Rank: 0\n",
      "Layer: 11 | #Rank: 2\n",
      "Layer: 12 | #Rank: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:42<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 12 | Validation accuracy: 0.06\n",
      "\n",
      "Training layer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:19<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 14!\n",
      "Validation started for 14\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 1\n",
      "Layer: 4 | #Rank: 0\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 1\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 2\n",
      "Layer: 10 | #Rank: 1\n",
      "Layer: 11 | #Rank: 2\n",
      "Layer: 12 | #Rank: 1\n",
      "Layer: 13 | #Rank: 14\n",
      "Layer: 14 | #Rank: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:44<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 14 | Validation accuracy: 0.38\n",
      "\n",
      "Training layer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:21<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 16!\n",
      "Validation started for 16\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 2\n",
      "Layer: 5 | #Rank: 2\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 6\n",
      "Layer: 10 | #Rank: 0\n",
      "Layer: 11 | #Rank: 1\n",
      "Layer: 12 | #Rank: 0\n",
      "Layer: 13 | #Rank: 11\n",
      "Layer: 14 | #Rank: 4\n",
      "Layer: 15 | #Rank: 8\n",
      "Layer: 16 | #Rank: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:45<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 16 | Validation accuracy: 0.69\n",
      "\n",
      "Training layer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:23<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 18!\n",
      "Validation started for 18\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 0\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 2\n",
      "Layer: 10 | #Rank: 0\n",
      "Layer: 11 | #Rank: 0\n",
      "Layer: 12 | #Rank: 1\n",
      "Layer: 13 | #Rank: 6\n",
      "Layer: 14 | #Rank: 0\n",
      "Layer: 15 | #Rank: 3\n",
      "Layer: 16 | #Rank: 13\n",
      "Layer: 17 | #Rank: 2\n",
      "Layer: 18 | #Rank: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:46<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 18 | Validation accuracy: 0.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(12, 20, 2):\n",
    "    mask = torch.ones(layer_idx+1, sing_vecs[layer_idx].shape[0], requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.01\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, alt_acts_charac, org_acts_state, org_acts_query_charac = defaultdict(dict), defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for l in range(layer_idx + 1):\n",
    "                        for t_idx, t in enumerate(charac_indices):\n",
    "                            alt_acts_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate(object_indices):\n",
    "                            alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(state_indices):\n",
    "                            org_acts_state[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate([-8, -7]):\n",
    "                            org_acts_query_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        for t_idx, t in enumerate(reversed_charac_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = alt_acts_charac[l][t_idx]\n",
    "\n",
    "                        sing_vec = sing_vecs[l].cuda()\n",
    "                        masked_vec = sing_vec * mask[l].unsqueeze(-1)\n",
    "                        proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "                        for t_idx, t in enumerate(reversed_object_indices):\n",
    "                            curr_output = model.model.layers[l].output[0][:, t].clone()\n",
    "                            alt_proj = torch.matmul(alt_acts[l][t_idx], proj_matrix)\n",
    "                            org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "                            modified_out = curr_output - org_proj + alt_proj\n",
    "                            model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                        for t_idx, t in enumerate([-8, -7]):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_query_charac[l][t_idx]\n",
    "\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(state_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_state[l][t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         for l in range(layer_idx+1):\n",
    "            #             mask[l].data.clamp_(0, 1)\n",
    "            #             rounded = torch.round(mask[l])\n",
    "            #             print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                for l in range(layer_idx+1):\n",
    "                    mask[l].data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "    rounded = torch.zeros(layer_idx+1, sing_vecs[layer_idx].shape[0], device=\"cuda\", dtype=torch.bfloat16)\n",
    "    with torch.inference_mode():\n",
    "        for l in range(layer_idx+1):\n",
    "            mask_data = mask[l].data.clone()\n",
    "            mask_data.clamp_(0, 1)\n",
    "            rounded[l] = torch.round(mask_data)\n",
    "            print(f\"Layer: {l} | #Rank: {(rounded[l] == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/object_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, alt_acts_charac, org_acts_state, org_acts_query_charac = defaultdict(dict), defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        for t_idx, t in enumerate(charac_indices):\n",
    "                            alt_acts_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate(object_indices):\n",
    "                            alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(state_indices):\n",
    "                            org_acts_state[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate([-8, -7]):\n",
    "                            org_acts_query_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        for t_idx, t in enumerate(reversed_charac_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = alt_acts_charac[l][t_idx]\n",
    "\n",
    "                        sing_vec = sing_vecs[l].cuda()\n",
    "                        masked_vec = sing_vec.to(rounded[l].device) * rounded[l].unsqueeze(-1)\n",
    "                        proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "                        for t_idx, t in enumerate(reversed_object_indices):\n",
    "                            curr_output = model.model.layers[l].output[0][:, t].clone()\n",
    "                            alt_proj = torch.matmul(alt_acts[l][t_idx], proj_matrix)\n",
    "                            org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "                            modified_out = curr_output - org_proj + alt_proj\n",
    "                            model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                        for t_idx, t in enumerate([-8, -7]):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_query_charac[l][t_idx]\n",
    "\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(state_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_state[l][t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.025,\n",
       " 5: 0.025,\n",
       " 10: 0.025,\n",
       " 12: 0.0625,\n",
       " 14: 0.375,\n",
       " 15: 0.375,\n",
       " 16: 0.6875,\n",
       " 18: 0.9,\n",
       " 20: 0.9125,\n",
       " 25: 0.9375,\n",
       " 30: 0.9125}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the valid_accs dict by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_charac_pos_exp(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Liz and Ray are working in a busy restaurant. To complete an order, Liz grabs an opaque pitcher and fills it with sprite. Then Ray grabs another opaque container and fills it with champagne.\n",
      "Question: What does Ray believe the container contains?\n",
      "Answer: champagne\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ray and Liz are working in a busy restaurant. To complete an order, Ray grabs an opaque container and fills it with milk. Then Liz grabs another opaque pitcher and fills it with monster.\n",
      "Question: What does Ray believe the pitcher contains?\n",
      "Answer: unknown\n",
      "Target:  monster\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dispenser and tun and\n",
      " tun and dispenser and\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['corrupt_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][object_indices]))\n",
    "\n",
    "tokens = model.tokenizer.encode(train_dataset[idx]['clean_prompt'], return_tensors=\"pt\").to(device)\n",
    "print(model.tokenizer.decode(tokens[0][object_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:27<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 12!\n",
      "Validation started for 12\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 1\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 2\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 1\n",
      "Layer: 7 | #Rank: 2\n",
      "Layer: 8 | #Rank: 1\n",
      "Layer: 9 | #Rank: 2\n",
      "Layer: 10 | #Rank: 5\n",
      "Layer: 11 | #Rank: 4\n",
      "Layer: 12 | #Rank: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:49<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 12 | Validation accuracy: 0.41\n",
      "\n",
      "Training layer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:30<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 14!\n",
      "Validation started for 14\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 1\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 1\n",
      "Layer: 5 | #Rank: 1\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 0\n",
      "Layer: 9 | #Rank: 1\n",
      "Layer: 10 | #Rank: 1\n",
      "Layer: 11 | #Rank: 3\n",
      "Layer: 12 | #Rank: 1\n",
      "Layer: 13 | #Rank: 10\n",
      "Layer: 14 | #Rank: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:51<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 14 | Validation accuracy: 0.78\n",
      "\n",
      "Training layer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:33<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 16!\n",
      "Validation started for 16\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 0\n",
      "Layer: 2 | #Rank: 0\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 0\n",
      "Layer: 5 | #Rank: 0\n",
      "Layer: 6 | #Rank: 0\n",
      "Layer: 7 | #Rank: 0\n",
      "Layer: 8 | #Rank: 0\n",
      "Layer: 9 | #Rank: 1\n",
      "Layer: 10 | #Rank: 1\n",
      "Layer: 11 | #Rank: 1\n",
      "Layer: 12 | #Rank: 2\n",
      "Layer: 13 | #Rank: 5\n",
      "Layer: 14 | #Rank: 5\n",
      "Layer: 15 | #Rank: 1\n",
      "Layer: 16 | #Rank: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:52<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 16 | Validation accuracy: 0.86\n",
      "\n",
      "Training layer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:36<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 18!\n",
      "Validation started for 18\n",
      "Layer: 0 | #Rank: 0\n",
      "Layer: 1 | #Rank: 1\n",
      "Layer: 2 | #Rank: 1\n",
      "Layer: 3 | #Rank: 0\n",
      "Layer: 4 | #Rank: 1\n",
      "Layer: 5 | #Rank: 1\n",
      "Layer: 6 | #Rank: 1\n",
      "Layer: 7 | #Rank: 1\n",
      "Layer: 8 | #Rank: 2\n",
      "Layer: 9 | #Rank: 3\n",
      "Layer: 10 | #Rank: 3\n",
      "Layer: 11 | #Rank: 4\n",
      "Layer: 12 | #Rank: 3\n",
      "Layer: 13 | #Rank: 7\n",
      "Layer: 14 | #Rank: 5\n",
      "Layer: 15 | #Rank: 0\n",
      "Layer: 16 | #Rank: 3\n",
      "Layer: 17 | #Rank: 2\n",
      "Layer: 18 | #Rank: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:54<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 18 | Validation accuracy: 0.76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(12, 20, 2):\n",
    "    mask = torch.ones(layer_idx+1, sing_vecs[layer_idx].shape[0], requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.01\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state, org_acts_query_obj = defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for l in range(layer_idx + 1):\n",
    "                        for t_idx, t in enumerate(charac_indices):\n",
    "                            alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(object_indices + state_indices):\n",
    "                            org_acts_state[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                        for t_idx, t in enumerate([-5, -4]):\n",
    "                            org_acts_query_obj[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        sing_vec = sing_vecs[l].cuda()\n",
    "                        masked_vec = sing_vec * mask[l].unsqueeze(-1)\n",
    "                        proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                        for t_idx, t in enumerate(reversed_charac_indices):\n",
    "                            curr_output = model.model.layers[l].output[0][:, t].clone()\n",
    "                            alt_proj = torch.matmul(alt_acts[l][t_idx], proj_matrix)\n",
    "                            org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                            modified_out = curr_output - org_proj + alt_proj\n",
    "                            model.model.layers[l].output[0][:, t] = modified_out\n",
    "                        \n",
    "                        for t_idx, t in enumerate([-5, -4]):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_query_obj[l][t_idx]\n",
    "                        \n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(object_indices + state_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_state[l][t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "            \n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         for l in range(layer_idx+1):\n",
    "            #             mask[l].data.clamp_(0, 1)\n",
    "            #             rounded = torch.round(mask[l])\n",
    "            #             print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                for l in range(layer_idx+1):\n",
    "                    mask[l].data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "    rounded = torch.zeros(layer_idx+1, sing_vecs[layer_idx].shape[0], device=\"cuda\", dtype=torch.bfloat16)\n",
    "    with torch.inference_mode():\n",
    "        for l in range(layer_idx+1):\n",
    "            mask_data = mask[l].data.clone()\n",
    "            mask_data.clamp_(0, 1)\n",
    "            rounded[l] = torch.round(mask_data)\n",
    "            print(f\"Layer: {l} | #Rank: {(rounded[l] == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/charac_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state, org_acts_query_charac = defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        for t_idx, t in enumerate(charac_indices):\n",
    "                            alt_acts[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(object_indices + state_indices):\n",
    "                            org_acts_state[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "                        \n",
    "                        for t_idx, t in enumerate([-5, -4]):\n",
    "                            org_acts_query_charac[l][t_idx] = model.model.layers[l].output[0][:, t].clone()\n",
    "\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    for l in range(layer_idx+1):\n",
    "                        sing_vec = sing_vecs[l].cuda()\n",
    "                        masked_vec = sing_vec.to(rounded[l].device) * rounded[l].unsqueeze(-1)\n",
    "                        proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                        for t_idx, t in enumerate(reversed_charac_indices):\n",
    "                            curr_output = model.model.layers[l].output[0][:, t].clone()\n",
    "                            alt_proj = torch.matmul(alt_acts[l][t_idx], proj_matrix)\n",
    "                            org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                            modified_out = curr_output - org_proj + alt_proj\n",
    "                            model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                        for t_idx, t in enumerate([-5, -4]):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_query_charac[l][t_idx]\n",
    "\n",
    "                    for l in range(model.config.num_hidden_layers):\n",
    "                        for t_idx, t in enumerate(object_indices + state_indices):\n",
    "                            model.model.layers[l].output[0][:, t] = org_acts_state[l][t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0625,\n",
       " 5: 0.0625,\n",
       " 10: 0.3375,\n",
       " 12: 0.4125,\n",
       " 14: 0.775,\n",
       " 15: 0.85,\n",
       " 16: 0.8625,\n",
       " 18: 0.7625,\n",
       " 20: 0.6875,\n",
       " 25: 0.675,\n",
       " 30: 0.5875}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = query_charac_pos(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Nick and Ruth are working in a busy restaurant. To complete an order, Nick grabs an opaque cup and fills it with bourbon. Then Ruth grabs another opaque pint and fills it with juice.\n",
      "Question: What does Nick believe the cup contains?\n",
      "Answer: bourbon\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ruth and Nick are working in a busy restaurant. To complete an order, Ruth grabs an opaque pint and fills it with tea. Then Nick grabs another opaque cup and fills it with soda.\n",
      "Question: What does Nick believe the pint contains?\n",
      "Answer: unknown\n",
      "Target:  tea\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Task Loss: -16.3281, L1 Loss: 25.0000, Total Loss: 8.6719\n",
      "#Causal SVs: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:03<00:27,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 2, Task Loss: -16.4219, L1 Loss: 19.8750, Total Loss: 5.7760\n",
      "#Causal SVs: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:06<00:24,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 4, Task Loss: -17.8125, L1 Loss: 14.8750, Total Loss: 2.7969\n",
      "#Causal SVs: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:09<00:21,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 6, Task Loss: -18.6406, L1 Loss: 9.8750, Total Loss: -0.1585\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:12<00:18,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 8, Task Loss: -17.1250, L1 Loss: 4.9375, Total Loss: -2.6997\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:15<00:15,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 10, Task Loss: -16.9844, L1 Loss: 0.0325, Total Loss: -5.1292\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:18<00:12,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 12, Task Loss: -16.9688, L1 Loss: 0.0236, Total Loss: -6.8436\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:21<00:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 14, Task Loss: -17.6875, L1 Loss: 0.0234, Total Loss: -8.3686\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:24<00:06,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 16, Task Loss: -18.9219, L1 Loss: 0.0237, Total Loss: -9.5523\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:27<00:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 18, Task Loss: -18.8281, L1 Loss: 0.0238, Total Loss: -10.3814\n",
      "#Causal SVs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 34!\n",
      "Validation started for 34\n",
      "#Rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 34 | Validation accuracy: 0.07\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(34, 36, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.025\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate([-8, -7]):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate([-8, -7]):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/query_charac_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate([-8, -7]):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate([-8, -7]):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = alt_acts[t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.075,\n",
       " 10: 0.0375,\n",
       " 12: 0.225,\n",
       " 14: 1.0,\n",
       " 16: 1.0,\n",
       " 18: 1.0,\n",
       " 20: 0.9,\n",
       " 30: 0.4625,\n",
       " 32: 0.1625,\n",
       " 34: 0.075}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = query_obj_pos(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Liz and Ray are working in a busy restaurant. To complete an order, Liz grabs an opaque pitcher and fills it with sprite. Then Ray grabs another opaque container and fills it with champagne.\n",
      "Question: What does Ray believe the container contains?\n",
      "Answer: champagne\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Ray and Liz are working in a busy restaurant. To complete an order, Ray grabs an opaque container and fills it with milk. Then Liz grabs another opaque pitcher and fills it with monster.\n",
      "Question: What does Liz believe the container contains?\n",
      "Answer: unknown\n",
      "Target:  monster\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 22!\n",
      "Validation started for 22\n",
      "#Rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 22 | Validation accuracy: 0.91\n",
      "\n",
      "Training layer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 24!\n",
      "Validation started for 24\n",
      "#Rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 24 | Validation accuracy: 0.93\n",
      "\n",
      "Training layer: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 26!\n",
      "Validation started for 26\n",
      "#Rank: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 26 | Validation accuracy: 0.90\n",
      "\n",
      "Training layer: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 28!\n",
      "Validation started for 28\n",
      "#Rank: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 28 | Validation accuracy: 0.75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(22, 30, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.05\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate([-5, -4]):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate([-5, -4]):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[l].output[0][:, t] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/query_obj_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate([-5, -4]):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate([-5, -4]):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = alt_acts[t_idx]\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 10: 0.0,\n",
       " 12: 0.0,\n",
       " 14: 0.6,\n",
       " 16: 0.6,\n",
       " 18: 0.8625,\n",
       " 20: 0.9,\n",
       " 22: 0.9125,\n",
       " 24: 0.925,\n",
       " 26: 0.9,\n",
       " 28: 0.75,\n",
       " 30: 0.2625}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct State Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_pos_trans_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Karen and Max are working in a busy restaurant. To complete an order, Karen grabs an opaque dispenser and fills it with coffee. Then Max grabs another opaque tun and fills it with cocoa.\n",
      "Question: What does Karen believe the dispenser contains?\n",
      "Answer: coffee\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Max and Karen are working in a busy restaurant. To complete an order, Max grabs an opaque tun and fills it with port. Then Karen grabs another opaque dispenser and fills it with water.\n",
      "Question: What does Karen believe the dispenser contains?\n",
      "Answer: water\n",
      "Target:  port\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 40!\n",
      "Validation started for 40\n",
      "#Rank: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 40 | Validation accuracy: 0.86\n",
      "\n",
      "Training layer: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:29<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 45!\n",
      "Validation started for 45\n",
      "#Rank: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 45 | Validation accuracy: 0.86\n",
      "\n",
      "Training layer: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 50!\n",
      "Validation started for 50\n",
      "#Rank: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 50 | Validation accuracy: 0.84\n",
      "\n",
      "Training layer: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:26<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 55!\n",
      "Validation started for 55\n",
      "#Rank: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 55 | Validation accuracy: 0.24\n",
      "\n",
      "Training layer: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:24<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 60!\n",
      "Validation started for 60\n",
      "#Rank: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 60 | Validation accuracy: 0.11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(40, 65, 5):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.1\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        # torch.save(rounded, f\"../masks/toy/correct_state_oid/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                    # model.model.layers[layer_idx].output[0][:, -1] = alt_acts\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    # valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{30: 0.0125,\n",
       " 32: 0.0,\n",
       " 34: 0.975,\n",
       " 36: 0.8,\n",
       " 38: 0.9625,\n",
       " 40: 0.0,\n",
       " 45: 0.0,\n",
       " 50: 0.0,\n",
       " 55: 0.025,\n",
       " 60: 0.0625}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_value_fetcher_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size,\n",
    "                             question_type=\"belief_question\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Max and Karen are working in a busy restaurant. To complete an order, Max grabs an opaque tun and fills it with port. Then Karen grabs another opaque dispenser and fills it with water.\n",
      "Question: What does Max believe the tun contains?\n",
      "Answer:  port\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Tony and Nancy are working in a busy restaurant. To complete an order, Tony grabs an opaque dispenser and fills it with stout. Then Nancy grabs another opaque can and fills it with juice.\n",
      "Question: What does Tony believe the dispenser contains?\n",
      "Answer:  stout\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_target'])\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 56!\n",
      "Validation started for 56\n",
      "#Rank: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 56 | Validation accuracy: 0.65\n",
      "\n",
      "Training layer: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 58!\n",
      "Validation started for 58\n",
      "#Rank: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 58 | Validation accuracy: 0.86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(56, 60, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.4\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"corrupt_target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # if bi % 2 == 0:\n",
    "            #     mean_loss = epoch_loss / (bi + 1)\n",
    "            #     print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "            #         f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "            #     with torch.no_grad():\n",
    "            #         mask.data.clamp_(0, 1)\n",
    "            #         rounded = torch.round(mask)\n",
    "            #         print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask_data)\n",
    "        print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "        # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "        torch.save(rounded, f\"../masks/toy/value_fetcher/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"corrupt_target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    alt_acts = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, -1].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts, proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, -1] = modified_out\n",
    "\n",
    "                    # model.model.layers[layer_idx].output[0][:, -1] = alt_acts\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                pred_token = model.tokenizer.decode(pred[i])\n",
    "                # print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "                if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "    valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: 0.0625,\n",
       " 55: 0.2625,\n",
       " 56: 0.65,\n",
       " 58: 0.8625,\n",
       " 60: 0.8375,\n",
       " 65: 0.95,\n",
       " 70: 0.9375,\n",
       " 75: 0.9875}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by key\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 80\n",
    "batch_size = 4\n",
    "\n",
    "dataset = get_unidirectional_visibility_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size+valid_size)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Tony and Nancy are working in a busy restaurant. To complete an order, Tony grabs an opaque tote and fills it with porter. Then Nancy grabs another opaque flask and fills it with cocoa. Nancy cannot observe Tony's actions. Tony can observe Nancy's actions.\n",
      "Question: What does Tony believe the flask contains?\n",
      "Answer: cocoa\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Eric and Joe are working in a busy restaurant. To complete an order, Eric grabs an opaque urn and fills it with port. Then Joe grabs another opaque bottle and fills it with coffee. Joe cannot observe Eric's actions. Eric cannot observe Joe's actions.\n",
      "Question: What does Eric believe the bottle contains?\n",
      "Answer: unknown\n",
      "Target:  coffee\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['corrupt_prompt'], dataset[idx]['corrupt_ans'])\n",
    "print(dataset[idx]['clean_prompt'], dataset[idx]['clean_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Task Loss: -15.2891, L1 Loss: 3.5000, Total Loss: -11.7891\n",
      "Rank: 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:04<00:40,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 2, Task Loss: -15.3984, L1 Loss: 2.9844, Total Loss: -12.1328\n",
      "Rank: 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:08<00:35,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 4, Task Loss: -15.5938, L1 Loss: 2.5312, Total Loss: -12.5359\n",
      "Rank: 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:13<00:29,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 6, Task Loss: -16.8594, L1 Loss: 2.0781, Total Loss: -13.0748\n",
      "Rank: 1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:17<00:25,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 8, Task Loss: -17.3281, L1 Loss: 1.6406, Total Loss: -13.5547\n",
      "Rank: 1187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:21<00:21,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 10, Task Loss: -17.4375, L1 Loss: 1.2266, Total Loss: -13.9574\n",
      "Rank: 1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:25<00:17,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 12, Task Loss: -17.5156, L1 Loss: 1.1328, Total Loss: -14.2987\n",
      "Rank: 1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:30<00:12,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 14, Task Loss: -17.6406, L1 Loss: 1.1172, Total Loss: -14.5958\n",
      "Rank: 1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:34<00:08,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 16, Task Loss: -17.4688, L1 Loss: 1.1016, Total Loss: -14.8396\n",
      "Rank: 1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:38<00:04,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 18, Task Loss: -17.4062, L1 Loss: 1.0938, Total Loss: -15.0613\n",
      "Rank: 1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:42<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 18!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "\n",
    "for layer_idx in range(18, 20, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    n_epochs = 1\n",
    "    lamb = 0.001\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompts = batch[\"corrupt_prompt\"]\n",
    "            org_prompts = batch[\"clean_prompt\"]\n",
    "            targets = batch[\"target\"]\n",
    "            target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "            batch_size = target_tokens.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(alt_prompts):\n",
    "                    for t_idx, t in enumerate(second_visibility_sent):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompts):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(second_visibility_sent):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "            target_logit = logits[torch.arange(batch_size), target_tokens]\n",
    "            task_loss = -torch.mean(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if bi % 2 == 0:\n",
    "                mean_loss = epoch_loss / (bi + 1)\n",
    "                print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "                    f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "                with torch.no_grad():\n",
    "                    mask.data.clamp_(0, 1)\n",
    "                    rounded = torch.round(mask)\n",
    "                    print(f\"Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation started for 18\n",
      "#Rank: 1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:01<00:24,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: bourbon, Target: bourbon\n",
      "Predicted: sprite, Target: sprite\n",
      "Predicted: unknown, Target: champagne\n",
      "Predicted: bourbon, Target: bourbon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:02<00:21,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: port, Target: port\n",
      "Predicted: unknown, Target: stout\n",
      "Predicted: espresso, Target: espresso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:03<00:19,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: unknown, Target: porter\n",
      "Predicted: water, Target: water\n",
      "Predicted: unknown, Target: porter\n",
      "Predicted: unknown, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:04<00:17,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: unknown, Target: porter\n",
      "Predicted: ale, Target: ale\n",
      "Predicted: gin, Target: gin\n",
      "Predicted: ale, Target: ale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:05<00:16,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: cocktail, Target: sprite\n",
      "Predicted: port, Target: port\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: cocktail, Target: cocktail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:06<00:15,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: rum, Target: rum\n",
      "Predicted: tea, Target: tea\n",
      "Predicted: porter, Target: porter\n",
      "Predicted: port, Target: port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:07<00:14,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: porter, Target: porter\n",
      "Predicted: unknown, Target: espresso\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: beer, Target: beer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:09<00:13,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: unknown, Target: stout\n",
      "Predicted: champagne, Target: champagne\n",
      "Predicted: unknown, Target: milk\n",
      "Predicted: port, Target: port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:10<00:12,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: champagne, Target: champagne\n",
      "Predicted: unknown, Target: milk\n",
      "Predicted: stout, Target: stout\n",
      "Predicted: soda, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:11<00:11,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ale, Target: ale\n",
      "Predicted: milk, Target: milk\n",
      "Predicted: unknown, Target: stout\n",
      "Predicted: coffee, Target: coffee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:12<00:10,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: monster, Target: monster\n",
      "Predicted: tea, Target: tea\n",
      "Predicted: tea, Target: tea\n",
      "Predicted: water, Target: water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:13<00:09,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: port, Target: port\n",
      "Predicted: espresso, Target: port\n",
      "Predicted: unknown, Target: port\n",
      "Predicted: soda, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:14<00:07,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: champagne, Target: champagne\n",
      "Predicted: water, Target: water\n",
      "Predicted: punch, Target: rum\n",
      "Predicted: unknown, Target: rum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:15<00:06,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tea, Target: tea\n",
      "Predicted: unknown, Target: bourbon\n",
      "Predicted: port, Target: port\n",
      "Predicted: monster, Target: monster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:17<00:05,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: punch, Target: punch\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: milk, Target: milk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:18<00:04,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tea, Target: tea\n",
      "Predicted: unknown, Target: wine\n",
      "Predicted: water, Target: water\n",
      "Predicted: sprite, Target: sprite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:19<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: espresso, Target: espresso\n",
      "Predicted: monster, Target: monster\n",
      "Predicted: unknown, Target: bourbon\n",
      "Predicted: soda, Target: soda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:20<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: stout, Target: stout\n",
      "Predicted: espresso, Target: espresso\n",
      "Predicted: unknown, Target: espresso\n",
      "Predicted: float, Target: float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:21<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: milk, Target: wine\n",
      "Predicted: sprite, Target: sprite\n",
      "Predicted: unknown, Target: cocoa\n",
      "Predicted: monster, Target: monster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: espresso, Target: espresso\n",
      "Predicted: water, Target: water\n",
      "Predicted: punch, Target: punch\n",
      "Predicted: unknown, Target: bourbon\n",
      "Layer: 18 | Validation accuracy: 0.71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation started for {layer_idx}\")\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    mask_data = mask.data.clone()\n",
    "    mask_data.clamp_(0, 1)\n",
    "    rounded = torch.round(mask_data)\n",
    "    print(f\"#Rank: {(rounded == 1).sum().item()}\")\n",
    "\n",
    "    # rank[layer_idx] = (rounded == 1).sum().item()\n",
    "    # torch.save(rounded, f\"../masks/toy/value_fetcher/{layer_idx}.pt\")\n",
    "\n",
    "    for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "        alt_prompts = batch[\"corrupt_prompt\"]\n",
    "        org_prompts = batch[\"clean_prompt\"]\n",
    "        targets = batch[\"target\"]\n",
    "        target_tokens = model.tokenizer(targets, return_tensors=\"pt\").input_ids[:, -1]\n",
    "        batch_size = target_tokens.size(0)\n",
    "\n",
    "        alt_acts, org_acts_state = defaultdict(dict), defaultdict(dict)\n",
    "        with model.trace() as tracer:\n",
    "            with tracer.invoke(alt_prompts):\n",
    "                for t_idx, t in enumerate(second_visibility_sent):\n",
    "                    alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "            with tracer.invoke(org_prompts):\n",
    "                sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                for t_idx, t in enumerate(second_visibility_sent):\n",
    "                    curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "                    alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                    org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                    modified_out = curr_output - org_proj + alt_proj\n",
    "                    model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    # model.model.layers[layer_idx].output[0][:, t] = alt_acts[t_idx]\n",
    "\n",
    "                del sing_vec, proj_matrix, masked_vec\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                logits = model.lm_head.output[:, -1].save()\n",
    "\n",
    "        pred = torch.argmax(logits, dim=-1).to(target_tokens.device).cpu()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            pred_token = model.tokenizer.decode(pred[i])\n",
    "            print(f\"Predicted: {pred_token.lower().strip()}, Target: {targets[i].lower().strip()}\")\n",
    "            if pred_token.lower().strip() == targets[i].lower().strip():\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "        del alt_acts, alt_prompts, org_prompts, targets, target_tokens, logits, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Layer: {layer_idx} | Validation accuracy: {correct / total:.2f}\\n\")\n",
    "# valid_accs[layer_idx] = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
