{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "env.yml not found in /disk/u/nikhil/mind!\n",
      "Setting MODEL_ROOT=\"\". Models will now be downloaded to conda env cache, if not already there\n",
      "Other defaults are set to:\n",
      "    DATA_DIR = \"data\"\n",
      "    RESULTS_DIR = \"results\"\n",
      "    HPARAMS_DIR = \"hparams\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Any, List, Optional\n",
    "import nnsight\n",
    "from nnsight import CONFIG, LanguageModel\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from einops import einsum\n",
    "import time\n",
    "from einops import rearrange, reduce\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.dataset import SampleV3, DatasetV3, STORY_TEMPLATES\n",
    "from src.utils import env_utils\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(10)\n",
    "\n",
    "CONFIG.set_default_api_key(\"d9e00ab7d4f74643b3176de0913f24a7\")\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "CONFIG.APP.REMOTE_LOGGING = False\n",
    "\n",
    "# Define random seed\n",
    "seed = 10\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = {}\n",
    "all_containers= {}\n",
    "all_characters = json.load(open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"synthetic_entities\", \"characters.json\"), \"r\"))\n",
    "\n",
    "for TYPE, DCT in {\"states\": all_states, \"containers\": all_containers}.items():\n",
    "    ROOT = os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \"synthetic_entities\", TYPE\n",
    "    )\n",
    "    for file in os.listdir(ROOT):\n",
    "        file_path = os.path.join(ROOT, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            names = json.load(f)\n",
    "        DCT[file.split(\".\")[0]] = names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:35<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# model = LanguageModel(\"meta-llama/Meta-Llama-3.1-405B\")\n",
    "model = LanguageModel(\"meta-llama/Meta-Llama-3-70B-Instruct\", cache_dir=\"/disk/u/nikhil/.cache/huggingface/hub/\", device_map=\"auto\", load_in_4bit=True, torch_dtype=torch.float16, dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ques_start_token_idx(tokenizer, prompt):      \n",
    "    input_tokens = tokenizer.encode(prompt, return_tensors=\"pt\").squeeze()\n",
    "    corrolary_token = tokenizer.encode(\":\", return_tensors=\"pt\").squeeze()[-1].item()\n",
    "    ques_start_idx = (input_tokens == corrolary_token).nonzero()[2].item()\n",
    "\n",
    "    return ques_start_idx-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_token_len(tokenizer, prompt):\n",
    "    input_tokens = tokenizer.encode(prompt, return_tensors=\"pt\").squeeze()\n",
    "    return len(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pred(pred, target, verbose=False):\n",
    "    prompt = f\"Instruction: Check if the following ground truth and prediction are same or different. If they are the same, then predict 'Yes', else 'No' \\n\\nGround truth: {target}\\nPrediction: {pred}\\nAnswer:\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with model.generate(prompt, max_new_tokens=5, do_sample=False, num_return_sequences=1, pad_token_id=model.tokenizer.pad_token_id):\n",
    "            out = model.generator.output.save()\n",
    "\n",
    "    prompt_len = get_prompt_token_len(model.tokenizer, prompt)\n",
    "    \n",
    "    if verbose:\n",
    "        print(model.tokenizer.decode(out[0]).strip())\n",
    "\n",
    "    return model.tokenizer.decode(out[0][prompt_len:-1]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading BigToM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a csv file\n",
    "df_false = pd.read_csv(\"../data/bigtom/0_forward_belief_false_belief/stories.csv\", delimiter=\";\")\n",
    "df_true = pd.read_csv(\"../data/bigtom/0_forward_belief_true_belief/stories.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row in the dataframe extract story, answer, and distractor\n",
    "true_stories, false_stories = [], []\n",
    "for i in range(len(df_true)):\n",
    "    story = df_true.iloc[i]['story']\n",
    "    question = df_true.iloc[i]['question']\n",
    "    answer = df_true.iloc[i]['answer']\n",
    "    distractor = df_true.iloc[i]['distractor']\n",
    "    true_stories.append({\"story\": story, \"question\": question, \"answer\": answer, \"distractor\": distractor})\n",
    "\n",
    "for i in range(len(df_false)):\n",
    "    story = df_false.iloc[i]['story']\n",
    "    question = df_true.iloc[i]['question']\n",
    "    answer = df_false.iloc[i]['answer']\n",
    "    distractor = df_false.iloc[i]['distractor']\n",
    "    false_stories.append({\"story\": story, \"question\": question, \"answer\": answer, \"distractor\": distractor})\n",
    "\n",
    "dataset = []\n",
    "instruction = \"1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any belief about the container or its content which they cannot observe directly. 4. To answer the question, predict only the final state of the queried container in fewest tokens possible, strictly based on the belief of the character, mentioned in the question. 5. Do not predict the entire sentence with character or container as the final output.\"\n",
    "\n",
    "for i in range(min(len(true_stories), len(false_stories))):\n",
    "    question = true_stories[i]['question']\n",
    "    visible_prompt = f\"Instructions: {instruction}\\n\\nStory: {true_stories[i]['story']}\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "    question = false_stories[i]['question']\n",
    "    invisible_prompt = f\"Instructions: {instruction}\\n\\nStory: {false_stories[i]['story']}\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "    visible_ans = true_stories[i]['answer'].split()\n",
    "    invisible_ans = false_stories[i]['answer'].split()\n",
    "\n",
    "    # Find the index of first word which is different in both answers\n",
    "    diff_idx = 0\n",
    "    for idx, (v, j) in enumerate(zip(visible_ans, invisible_ans)):\n",
    "        if v != j:\n",
    "            diff_idx = idx\n",
    "            break\n",
    "    \n",
    "    visible_ans = \" \".join(visible_ans[diff_idx:])[:-1]\n",
    "    invisible_ans = \" \".join(invisible_ans[diff_idx:])[:-1]\n",
    "\n",
    "    visible_ans_one_word = \" \".join(visible_ans[diff_idx:diff_idx+1])\n",
    "    invisible_ans_one_word = \" \".join(invisible_ans[diff_idx:diff_idx+1])\n",
    "\n",
    "    visible_ans_one_word = visible_ans[:-1] if visible_ans[-1] == \".\" else visible_ans\n",
    "    invisible_ans_one_word = invisible_ans[:-1] if invisible_ans[-1] == \".\" else invisible_ans\n",
    "\n",
    "    dataset.append({\n",
    "        \"alt_story\": true_stories[i]['story'],\n",
    "        \"alt_question\": true_stories[i]['question'],\n",
    "        \"alt_prompt\": visible_prompt,\n",
    "        \"alt_ans\": visible_ans,\n",
    "        \"org_story\": false_stories[i]['story'],\n",
    "        \"org_question\": false_stories[i]['question'],\n",
    "        \"org_prompt\": invisible_prompt,\n",
    "        \"org_ans\": invisible_ans,\n",
    "        \"target\": visible_ans,\n",
    "    })\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any belief about the container or its content which they cannot observe directly. 4. To answer the question, predict only the final state of the queried container in fewest tokens possible, strictly based on the belief of the character, mentioned in the question. 5. Do not predict the entire sentence with character or container as the final output.\n",
      "\n",
      "Story: Noor is working as a barista at a busy coffee shop. Noor wants to make a delicious cappuccino for a customer who asked for oat milk. Noor grabs a milk pitcher and fills it with oat milk. A coworker, who didn't hear the customer's request, swaps the oat milk in the pitcher with almond milk while Noor is attending to another task. Noor sees her coworker swapping the milk.\n",
      "Question: Does Noor believe the milk pitcher contains oat milk or almond milk?\n",
      "Answer: almond milk\n",
      "Instructions: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any belief about the container or its content which they cannot observe directly. 4. To answer the question, predict only the final state of the queried container in fewest tokens possible, strictly based on the belief of the character, mentioned in the question. 5. Do not predict the entire sentence with character or container as the final output.\n",
      "\n",
      "Story: Noor is working as a barista at a busy coffee shop. Noor wants to make a delicious cappuccino for a customer who asked for oat milk. Noor grabs a milk pitcher and fills it with oat milk. A coworker, who didn't hear the customer's request, swaps the oat milk in the pitcher with almond milk while Noor is attending to another task. Noor does not see her coworker swapping the milk.\n",
      "Question: Does Noor believe the milk pitcher contains oat milk or almond milk?\n",
      "Answer: oat milk\n",
      "Target: almond milk\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['alt_prompt'], dataset[idx]['alt_ans'])\n",
    "print(dataset[idx]['org_prompt'], dataset[idx]['org_ans'])\n",
    "print(f\"Target: {dataset[idx]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 80\n",
    "valid_size = 20\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "valid_dataset = dataset[train_size:train_size+valid_size]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 40\n",
    "valid_size = 20\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset = get_visibility_align_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             train_size,\n",
    "                             question_type=\"belief_question\",\n",
    "                             diff_visibility=True)\n",
    "valid_dataset = get_visibility_align_exps(STORY_TEMPLATES,\n",
    "                             all_characters,\n",
    "                             all_containers,\n",
    "                             all_states,\n",
    "                             valid_size,\n",
    "                             question_type=\"belief_question\",\n",
    "                             diff_visibility=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=valid_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Max and Karen are working in a busy restaurant. To complete an order, Max grabs an opaque tun and fills it with coffee. Then Karen grabs another opaque dispenser and fills it with cocoa. They are working side by side and can clearly observe each other's actions.\n",
      "Question: What does Karen believe the tun contains?\n",
      "Answer: coffee\n",
      "Instruction: 1. Track the belief of each character as described in the story. 2. A character's belief is formed only when they perform an action themselves or can observe the action taking place. 3. A character does not have any beliefs about the container and its contents which they cannot observe. 4. To answer the question, predict only what is inside the queried container, strictly based on the belief of the character, mentioned in the question. 5. If the queried character has no belief about the container in question, then predict 'unknown'. 6. Do not predict container or character as the final output.\n",
      "\n",
      "Story: Max and Karen are working in a busy restaurant. To complete an order, Max grabs an opaque tun and fills it with port. Then Karen grabs another opaque dispenser and fills it with water. They are working in the entirely separate sections, with no visibility between them.\n",
      "Question: What does Karen believe the tun contains?\n",
      "Answer: unknown\n",
      " port\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(train_dataset[idx]['corrupt_prompt'], train_dataset[idx]['corrupt_ans'])\n",
    "print(train_dataset[idx]['clean_prompt'], train_dataset[idx]['clean_ans'])\n",
    "print(train_dataset[idx]['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Singular Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vecs = defaultdict(dict)\n",
    "for l in range(41):\n",
    "    sing_vecs[l] = torch.load(f\"../svd_results/bigtom/singular_vecs/{l}.pt\").cpu()\n",
    "    # sing_vecs[l] = torch.load(f\"../svd_results/toy/singular_vecs/{l}.pt\").cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m org_prompt_len \u001b[38;5;241m=\u001b[39m get_prompt_token_len(model\u001b[38;5;241m.\u001b[39mtokenizer, org_prompt)\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrace() \u001b[38;5;28;01mas\u001b[39;00m tracer:\n\u001b[1;32m     31\u001b[0m     alt_acts \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39minvoke(alt_prompt):\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/intervention/contexts/interleaving.py:96\u001b[0m, in \u001b[0;36mInterleavingTracer.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39m_envoy\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/tracing/contexts/tracer.py:25\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglobals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalTracingContext\n\u001b[1;32m     23\u001b[0m GlobalTracingContext\u001b[38;5;241m.\u001b[39mtry_deregister(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/tracing/contexts/base.py:82\u001b[0m, in \u001b[0;36mContext.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     78\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m     80\u001b[0m graph\u001b[38;5;241m.\u001b[39malive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/tracing/backends/base.py:25\u001b[0m, in \u001b[0;36mExecutionBackend.__call__\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph: Graph) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minjection:\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontexts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Context\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/tracing/graph/node.py:289\u001b[0m, in \u001b[0;36mNode.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget, Protocol):\n\u001b[0;32m--> 289\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m         \u001b[38;5;66;03m# Prepare arguments.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m         args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs))\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/intervention/contexts/interleaving.py:161\u001b[0m, in \u001b[0;36mInterleavingTracer.execute\u001b[0;34m(cls, node)\u001b[0m\n\u001b[1;32m    157\u001b[0m graph\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[1;32m    159\u001b[0m interleaver \u001b[38;5;241m=\u001b[39m Interleaver(graph, batch_groups\u001b[38;5;241m=\u001b[39mbatch_groups)\n\u001b[0;32m--> 161\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterleaver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minvoker_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minvoker_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m graph\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/modeling/mixins/meta.py:51\u001b[0m, in \u001b[0;36mMetaMixin.interleave\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatched:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch()\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterleave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/intervention/base.py:340\u001b[0m, in \u001b[0;36mNNsight.interleave\u001b[0;34m(self, interleaver, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m interleaver:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/nnsight/modeling/language.py:297\u001b[0m, in \u001b[0;36mLanguageModel._execute\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: BatchEncoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    295\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:834\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 834\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:592\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    581\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    582\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m         position_embeddings,\n\u001b[1;32m    590\u001b[0m     )\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:335\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/disk/u/nikhil/.conda/envs/tomi/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:274\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    273\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 274\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# valid_accs, rank = {}, {}\n",
    "\n",
    "for layer_idx in range(22 , 28, 2):\n",
    "    modules = [i for i in range(sing_vecs[layer_idx].shape[0])]\n",
    "    mask = torch.ones(len(modules), requires_grad=True, device=\"cuda\", dtype=torch.bfloat16)\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-1)\n",
    "    \n",
    "    n_epochs = 1\n",
    "    lamb = 0.0275\n",
    "\n",
    "    print(f\"Training layer: {layer_idx}\")\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for bi, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            alt_prompt = batch[\"alt_prompt\"][0]\n",
    "            org_prompt = batch[\"org_prompt\"][0]\n",
    "            target = batch[\"target\"][0]\n",
    "            target_token = model.tokenizer(target, return_tensors=\"pt\", padding=True, padding_side=\"right\").input_ids[0, 1:]\n",
    "            batch_size = target_token.shape[0]\n",
    "\n",
    "            alt_ques_idx = get_ques_start_token_idx(model.tokenizer, alt_prompt)\n",
    "            alt_prompt_len = get_prompt_token_len(model.tokenizer, alt_prompt)\n",
    "            org_ques_idx = get_ques_start_token_idx(model.tokenizer, org_prompt)\n",
    "            org_prompt_len = get_prompt_token_len(model.tokenizer, org_prompt)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with model.trace() as tracer:\n",
    "\n",
    "                alt_acts = defaultdict(dict)\n",
    "                with tracer.invoke(alt_prompt):\n",
    "                    for t_idx, t in enumerate(range(alt_ques_idx, alt_prompt_len)):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][0, t].clone()\n",
    "\n",
    "                with tracer.invoke(org_prompt):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec * mask.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(range(org_ques_idx, org_prompt_len)):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][0, t].clone()\n",
    "                        \n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][0, t] = modified_out\n",
    "                    \n",
    "                    del sing_vec, proj_matrix, masked_vec\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    logits = model.lm_head.output[0, -1].save()\n",
    "            \n",
    "            target_logit = logits[target_token]\n",
    "\n",
    "            task_loss = -torch.sum(target_logit)\n",
    "            l1_loss = lamb * torch.norm(mask, p=1)\n",
    "            loss = task_loss + l1_loss.to(task_loss.device)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if bi % (len(train_dataloader)//5) == 0:\n",
    "                mean_loss = epoch_loss / (bi + 1)\n",
    "                print(f\"Epoch: {epoch}, Batch: {bi}, Task Loss: {task_loss.item():.4f}, \"\n",
    "                    f\"L1 Loss: {l1_loss.item():.4f}, Total Loss: {mean_loss:.4f}\")\n",
    "                with torch.no_grad():\n",
    "                    mask.data.clamp_(0, 1)\n",
    "                    rounded = torch.round(mask)\n",
    "                    print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clamp after optimizer step\n",
    "            with torch.no_grad():\n",
    "                mask.data.clamp_(0, 1)\n",
    "\n",
    "    print(f\"Training complete for {layer_idx}!\")\n",
    "\n",
    "    print(f\"Validation started for layer: {layer_idx}\")\n",
    "    correct, total = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        mask_data = mask.data.clone()\n",
    "        mask_data.clamp_(0, 1)\n",
    "        rounded = torch.round(mask)\n",
    "        print(f\"#Causal SVs: {(rounded == 1).sum().item()}\")\n",
    "        rank[layer_idx] = (rounded == 1).sum().item()\n",
    "\n",
    "        # Save rounded on disk\n",
    "        torch.save(rounded, f\"../masks/bigtom/{layer_idx}.pt\")\n",
    "\n",
    "        for bi, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            alt_prompt = batch[\"alt_prompt\"][0]\n",
    "            org_prompt = batch[\"org_prompt\"][0]\n",
    "            alt_ans = batch[\"alt_ans\"][0]\n",
    "            batch_size = 1\n",
    "\n",
    "            alt_ques_idx = get_ques_start_token_idx(model.tokenizer, alt_prompt)\n",
    "            alt_prompt_len = get_prompt_token_len(model.tokenizer, alt_prompt)\n",
    "            org_ques_idx = get_ques_start_token_idx(model.tokenizer, org_prompt)\n",
    "            org_prompt_len = get_prompt_token_len(model.tokenizer, org_prompt)\n",
    "\n",
    "            with model.session() as session:\n",
    "\n",
    "                alt_acts = defaultdict(dict)\n",
    "                with model.trace(alt_prompt):\n",
    "                    for t_idx, t in enumerate(range(alt_ques_idx, alt_prompt_len)):\n",
    "                        alt_acts[t_idx] = model.model.layers[layer_idx].output[0][:, t].save()\n",
    "\n",
    "                with model.generate(org_prompt, max_new_tokens=8, do_sample=False, num_return_sequences=1, eos_token_id=model.tokenizer.eos_token_id, pad_token_id=model.tokenizer.pad_token_id):\n",
    "                    sing_vec = sing_vecs[layer_idx].cuda()\n",
    "                    masked_vec = sing_vec.to(rounded.device) * rounded.unsqueeze(-1)\n",
    "                    proj_matrix = torch.matmul(masked_vec.t(), masked_vec).half()\n",
    "\n",
    "                    for t_idx, t in enumerate(range(org_ques_idx, org_prompt_len)):\n",
    "                        curr_output = model.model.layers[layer_idx].output[0][:, t].clone()\n",
    "\n",
    "                        alt_proj = torch.matmul(alt_acts[t_idx], proj_matrix)\n",
    "                        org_proj = torch.matmul(curr_output, proj_matrix)\n",
    "\n",
    "                        modified_out = curr_output - org_proj + alt_proj\n",
    "                        model.model.layers[layer_idx].output[0][:, t] = modified_out\n",
    "\n",
    "                    out = model.generator.output.save()\n",
    "\n",
    "                    del sing_vec, proj_matrix\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                check = check_pred(model.tokenizer.decode(out[0][org_prompt_len:-1]), alt_ans, verbose=True)\n",
    "                # print(f\"Check: {check}\")\n",
    "                if check == \"Yes\":\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            \n",
    "            del alt_acts, alt_prompt, org_prompt, alt_ans, out\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        acc = round(correct/total, 2)\n",
    "        print(f\"Validation accuracy: {acc}\\n\")\n",
    "        valid_accs[layer_idx] = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0.0,\n",
       "  10: 0.0,\n",
       "  20: 0.0,\n",
       "  22: 0.0,\n",
       "  24: 0.0,\n",
       "  26: 0.1,\n",
       "  28: 0.35,\n",
       "  30: 0.55,\n",
       "  32: 0.75},\n",
       " {0: 68, 10: 71, 20: 62, 22: 50, 24: 105, 26: 75, 28: 88, 30: 78, 32: 85})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort valid_accs by keys\n",
    "valid_accs = dict(sorted(valid_accs.items()))\n",
    "rank = dict(sorted(rank.items()))\n",
    "valid_accs, rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3984, 1.0000, 0.4980, 0.0427, 0.0000, 0.5078, 0.0000, 0.3281, 1.0000,\n",
       "        1.0000, 1.0000, 0.8906, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.6758,\n",
       "        1.0000, 0.0000, 0.8594, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
       "        0.1328, 0.1426, 1.0000, 0.0000, 0.6797, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.6953, 0.3477, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.9062, 0.1855,\n",
       "        0.0000, 0.0000, 0.0000, 0.5352, 0.8242, 0.0000, 0.8750, 0.9141, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.5703, 0.0000, 0.9102, 0.0000, 0.0000, 0.0000,\n",
       "        1.0000, 0.0000, 0.0000, 0.7734, 0.0000, 0.0000, 0.0000, 0.0000, 0.9570,\n",
       "        0.0000, 0.5352, 0.0000, 0.0000, 0.0000, 0.6836, 0.0000, 1.0000, 0.0000,\n",
       "        0.4453, 1.0000, 0.0000, 0.0000, 0.8516, 0.5352, 1.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.8047, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[:100]\n",
    "# 0.025: 0.75 (4 epochs) | 104 SVs\n",
    "# 0.03: 0.75 (4 epochs) | 81 Svs *\n",
    "# 0.035: 0.65 (4 epochs) | 71 svs\n",
    "# 0.04: 0.35 (4 epochs) | 61 svs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_stories = [\n",
    "    {\n",
    "        \"story\": train_dataset[0][\"alt_story\"],\n",
    "        \"question\": train_dataset[0][\"alt_question\"],\n",
    "        \"answer\": train_dataset[0][\"alt_ans\"],\n",
    "    },\n",
    "    {\n",
    "        \"story\": train_dataset[0][\"org_story\"],\n",
    "        \"question\": train_dataset[0][\"org_question\"],\n",
    "        \"answer\": train_dataset[0][\"org_ans\"],\n",
    "    }\n",
    "]\n",
    "\n",
    "# arrows = [{'start': token_pos_coords['e1_query_charac'], 'end': token_pos_coords['e2_query_charac'], 'color': 'red'}]\n",
    "\n",
    "plot_data = {\n",
    "    \"labels\": valid_accs.keys(),\n",
    "    \"acc_one_layer\": valid_accs.values(),\n",
    "    \"title\": \"Aligning Visibility info\",\n",
    "    \"x_label\": \"Layers\",\n",
    "    \"y_label\": \"Intervention Accuracy\",\n",
    "}\n",
    "\n",
    "# characters = list(set(train_dataset[0]['clean_characters'] + train_dataset[0]['corrupt_characters']))\n",
    "# objects = list(set(train_dataset[0]['clean_objects'] + train_dataset[0]['corrupt_objects']))\n",
    "# states = list(set(train_dataset[0]['clean_states'] + train_dataset[0]['corrupt_states']))\n",
    "\n",
    "generator = StoryGenerator(characters=['Noor'], objects=['pitcher'], states=['oat', 'almond'], stories=true_stories, target=train_dataset[0]['alt_ans'], arrows=[], plot_data=plot_data)\n",
    "generator.save_html(filename=\"../plots/visibility_exps/bigtom/visible_to_invisible_dcm.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
